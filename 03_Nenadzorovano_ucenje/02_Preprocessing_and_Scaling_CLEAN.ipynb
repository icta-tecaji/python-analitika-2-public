{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab3dffc",
   "metadata": {},
   "source": [
    "# Preprocessing and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e3108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8563b0",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15031371",
   "metadata": {},
   "source": [
    "### Different Kinds of Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d85a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import plot_scaling\n",
    "\n",
    "plot_scaling.plot_scaling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32415b7",
   "metadata": {},
   "source": [
    "### Applying Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc221ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea41652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ad014",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dataset properties before and after scaling\n",
    "print(f\"transformed shape: {X_train_scaled.shape}\")\n",
    "print(f\"per-feature minimum before scaling:\\n {X_train.min(axis=0)}\")\n",
    "print(f\"per-feature maximum before scaling:\\n {X_train.max(axis=0)}\")\n",
    "print(f\"per-feature minimum after scaling:\\n {X_train_scaled.min(axis=0)}\")\n",
    "print(f\"per-feature maximum after scaling:\\n {X_train_scaled.max(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# print test data properties after scaling\n",
    "print(f\"per-feature minimum after scaling:\\n{X_test_scaled.min(axis=0)}\")\n",
    "print(f\"per-feature maximum after scaling:\\n{X_test_scaled.max(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff7e97",
   "metadata": {},
   "source": [
    "### Scaling Training and Test Data the Same Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6fc7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141af824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make synthetic data\n",
    "X, _ = make_blobs(n_samples=50, centers=5, random_state=4, cluster_std=2)\n",
    "\n",
    "# split it into training and test sets\n",
    "X_train, X_test = train_test_split(X, random_state=5, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8518142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and test sets\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 4))\n",
    "axes[0].scatter(X_train[:, 0], X_train[:, 1], c=\"blue\", label=\"Training set\", s=60)\n",
    "axes[0].scatter(X_test[:, 0], X_test[:, 1], marker='^', c=\"red\", label=\"Test set\", s=60)\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].set_title(\"Original Data\")\n",
    "\n",
    "# scale the data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# visualize the properly scaled data\n",
    "axes[1].scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=\"blue\", label=\"Training set\", s=60)\n",
    "axes[1].scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], marker='^',c=\"red\", label=\"Test set\", s=60)\n",
    "axes[1].set_title(\"Scaled Data\")\n",
    "\n",
    "# rescale the test set separately\n",
    "# so test set min is 0 and test set max is 1\n",
    "# DO NOT DO THIS! For illustration purposes only.\n",
    "test_scaler = MinMaxScaler()\n",
    "test_scaler.fit(X_test)\n",
    "X_test_scaled_badly = test_scaler.transform(X_test)\n",
    "\n",
    "# visualize wrongly scaled data\n",
    "axes[2].scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=\"blue\", label=\"training set\", s=60)\n",
    "axes[2].scatter(X_test_scaled_badly[:, 0], X_test_scaled_badly[:, 1], marker='^', c=\"red\", label=\"test set\", s=60)\n",
    "axes[2].set_title(\"Improperly Scaled Data\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Feature 0\")\n",
    "    ax.set_ylabel(\"Feature 1\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b44697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# calling fit and transform in sequence (using method chaining)\n",
    "X_scaled = scaler.fit(X).transform(X)\n",
    "\n",
    "# same result, but more efficient computation\n",
    "X_scaled_d = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0661971",
   "metadata": {},
   "source": [
    "### The Effect of Preprocessing on Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "svm = SVC(C=100)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Test set accuracy: {svm.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing using 0-1 scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# learning an SVM on the scaled training data\n",
    "svm = SVC(C=100)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# scoring on the scaled test set\n",
    "print(f\"Scaled test set accuracy: {svm.score(X_test_scaled, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0027d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing using zero mean and unit variance scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# learning an SVM on the scaled training data\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# scoring on the scaled test set\n",
    "print(f\"Test set accuracy: {svm.score(X_test_scaled, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ccb06",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_pca import plot_pca_illustration\n",
    "\n",
    "plot_pca_illustration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb17ce3",
   "metadata": {},
   "source": [
    "### Applying PCA to the cancer dataset for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import plot_helpers\n",
    "\n",
    "fig, axes = plt.subplots(15, 2, figsize=(10, 20))\n",
    "malignant = cancer.data[cancer.target == 0]\n",
    "benign = cancer.data[cancer.target == 1]\n",
    "ax = axes.ravel()\n",
    "\n",
    "for i in range(30):\n",
    "    _, bins = np.histogram(cancer.data[:, i], bins=50)\n",
    "    ax[i].hist(malignant[:, i], bins=bins, color=plot_helpers.cm3(0), alpha=.5)\n",
    "    ax[i].hist(benign[:, i], bins=bins, color=plot_helpers.cm3(2), alpha=.5)\n",
    "    ax[i].set_title(cancer.feature_names[i])\n",
    "    ax[i].set_yticks(())\n",
    "    \n",
    "ax[0].set_xlabel(\"Feature magnitude\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[0].legend([\"malignant\", \"benign\"], loc=\"best\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275d1d76",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(cancer.data)\n",
    "X_scaled = scaler.transform(cancer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# keep the first two principal components of the data\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# fit PCA model to breast cancer data\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aaefb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data onto the first two principal components\n",
    "X_pca = pca.transform(X_scaled)\n",
    "print(f\"Original shape: {str(X_scaled.shape)}\")\n",
    "print(f\"Reduced shape: {str(X_pca.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb14058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_helpers import discrete_scatter\n",
    "\n",
    "# plot first vs. second principal component, colored by class\n",
    "plt.figure(figsize=(8, 8))\n",
    "discrete_scatter(X_pca[:, 0], X_pca[:, 1], cancer.target)\n",
    "\n",
    "plt.legend(cancer.target_names, loc=\"best\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PCA component shape: {pca.components_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbcb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PCA components:\\n{pca.components_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1696d",
   "metadata": {},
   "source": [
    "### Eigenfaces for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de208157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "people = fetch_lfw_people(min_faces_per_person=20, resize=0.7)\n",
    "image_shape = people.images[0].shape\n",
    "\n",
    "fix, axes = plt.subplots(2, 5, figsize=(15, 8), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "\n",
    "for target, image, ax in zip(people.target, people.images, axes.ravel()):\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(people.target_names[target])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"people.images.shape: {people.images.shape}\")\n",
    "print(f\"Number of classes: {len(people.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how often each target appears\n",
    "counts = np.bincount(people.target)\n",
    "\n",
    "# print counts next to target names\n",
    "for i, (count, name) in enumerate(zip(counts, people.target_names)):\n",
    "    print(f\"{name:25} {count:3}\", end=' ')\n",
    "    if (i + 1) % 3 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(people.target.shape, dtype=bool)\n",
    "\n",
    "for target in np.unique(people.target):\n",
    "    mask[np.where(people.target == target)[0][:50]] = 1\n",
    "\n",
    "X_people = people.data[mask]\n",
    "y_people = people.target[mask]\n",
    "\n",
    "# scale the grayscale values to be between 0 and 1\n",
    "# instead of 0 and 255 for better numeric stability\n",
    "X_people = X_people / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0702e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_people, y_people, stratify=y_people, random_state=0)\n",
    "\n",
    "# build a KNeighborsClassifier using one neighbor\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Test set score of 1-nn: {knn.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e68c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_pca import plot_pca_whitening\n",
    "\n",
    "plot_pca_whitening()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100, whiten=True, random_state=0).fit(X_train)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train_pca.shape: {X_train_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train_pca, y_train)\n",
    "\n",
    "print(f\"Test set accuracy: {knn.score(X_test_pca, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"pca.components_.shape: {pca.components_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(3, 5, figsize=(15, 12), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "\n",
    "for i, (component, ax) in enumerate(zip(pca.components_, axes.ravel())):\n",
    "    ax.imshow(component.reshape(image_shape), cmap='viridis')\n",
    "    ax.set_title(\"{}. component\".format((i + 1)))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e015e90c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_pca import plot_pca_faces\n",
    "\n",
    "plot_pca_faces(X_train, X_test, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ada25",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_scatter(X_train_pca[:, 0], X_train_pca[:, 1], y_train)\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e1c36c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1fdc4",
   "metadata": {},
   "source": [
    "## Non-Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a96cc",
   "metadata": {},
   "source": [
    "### Applying NMF to synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_nmf import plot_nmf_illustration\n",
    "\n",
    "plot_nmf_illustration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c6d47",
   "metadata": {},
   "source": [
    "### Example: Dimensionality Reduction in Eurovision Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba64ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eurovision = pd.read_csv(\"data/eurovision-2016.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751eb425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e7900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de03ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11edb096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb1f278b",
   "metadata": {},
   "source": [
    "## Manifold Learning with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09123bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5), subplot_kw={'xticks':(), 'yticks': ()})\n",
    "\n",
    "for ax, img in zip(axes.ravel(), digits.images):\n",
    "    ax.imshow(img)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a PCA model\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(digits.data)\n",
    "\n",
    "# transform the digits data onto the first two principal components\n",
    "digits_pca = pca.transform(digits.data)\n",
    "\n",
    "colors = [\"#476A2A\", \"#7851B8\", \"#BD3430\", \"#4A2D4E\", \"#875525\", \"#A83683\", \"#4E655E\", \"#853541\", \"#3A3120\", \"#535D8E\"]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.xlim(digits_pca[:, 0].min(), digits_pca[:, 0].max())\n",
    "plt.ylim(digits_pca[:, 1].min(), digits_pca[:, 1].max())\n",
    "\n",
    "for i in range(len(digits.data)):\n",
    "    # actually plot the digits as text instead of using scatter\n",
    "    plt.text(digits_pca[i, 0], digits_pca[i, 1], str(digits.target[i]), color = colors[digits.target[i]], fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, learning_rate=200, init=\"random\", random_state=42)\n",
    "\n",
    "# use fit_transform instead of fit, as TSNE has no transform method\n",
    "digits_tsne = tsne.fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.xlim(digits_tsne[:, 0].min(), digits_tsne[:, 0].max() + 1)\n",
    "plt.ylim(digits_tsne[:, 1].min(), digits_tsne[:, 1].max() + 1)\n",
    "\n",
    "for i in range(len(digits.data)):\n",
    "    # actually plot the digits as text instead of using scatter\n",
    "    plt.text(digits_tsne[i, 0], digits_tsne[i, 1], str(digits.target[i]), color = colors[digits.target[i]], fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "plt.xlabel(\"t-SNE feature 0\")\n",
    "plt.xlabel(\"t-SNE feature 1\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
