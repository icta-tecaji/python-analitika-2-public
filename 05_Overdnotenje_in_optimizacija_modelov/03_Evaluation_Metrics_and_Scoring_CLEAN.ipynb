{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7abe83",
   "metadata": {},
   "source": [
    "# Evaluation Metrics and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b8d5db",
   "metadata": {},
   "source": [
    "## Upoštevanje končnega cilja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29ef38",
   "metadata": {},
   "source": [
    "## Metrics for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00f91d",
   "metadata": {},
   "source": [
    "### Kinds of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b000aeb",
   "metadata": {},
   "source": [
    "### Imbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "y = digits.target == 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "pred_most_frequent = dummy_majority.predict(X_test)\n",
    "\n",
    "print(f\"Unique predicted labels: {np.unique(pred_most_frequent)}\")\n",
    "print(f\"Test score: {dummy_majority.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c52da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
    "pred_tree = tree.predict(X_test)\n",
    "\n",
    "print(f\"Test score: {tree.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e55913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"stratified\", random_state=42).fit(X_train, y_train)\n",
    "pred_dummy = dummy.predict(X_test)\n",
    "print(f\"dummy score: {dummy.score(X_test, y_test):.2f}\")\n",
    "\n",
    "logreg = LogisticRegression(C=0.1, max_iter=10000, solver=\"liblinear\").fit(X_train, y_train)\n",
    "pred_logreg = logreg.predict(X_test)\n",
    "print(f\"logreg score: {logreg.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b670c68f",
   "metadata": {},
   "source": [
    "### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a085a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "\n",
    "print(f\"Confusion matrix:\\n{confusion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81cd847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_metrics import plot_confusion_matrix_illustration\n",
    "\n",
    "plot_confusion_matrix_illustration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_metrics import plot_binary_confusion_matrix\n",
    "\n",
    "plot_binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae46bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Most frequent class:\")\n",
    "print(confusion_matrix(y_test, pred_most_frequent))\n",
    "print(\"\\nDummy model:\")\n",
    "print(confusion_matrix(y_test, pred_dummy))\n",
    "print(\"\\nDecision tree:\")\n",
    "print(confusion_matrix(y_test, pred_tree))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(confusion_matrix(y_test, pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d943176",
   "metadata": {},
   "source": [
    "**Relation to accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d6be0",
   "metadata": {},
   "source": [
    "**Precision, recall, and f-score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6814b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"f1 score most frequent: {:.2f}\".format(f1_score(y_test, pred_most_frequent)))\n",
    "print(\"f1 score dummy: {:.2f}\".format(f1_score(y_test, pred_dummy)))\n",
    "print(\"f1 score tree: {:.2f}\".format(f1_score(y_test, pred_tree)))\n",
    "print(\"f1 score logistic regression: {:.2f}\".format(f1_score(y_test, pred_logreg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c40520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_most_frequent, target_names=[\"not nine\", \"nine\"], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc859c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_dummy, target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fce281",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_logreg, target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43ae52",
   "metadata": {},
   "source": [
    "### Taking uncertainty into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = make_blobs(n_samples=(400, 50), cluster_std=[7.0, 2], random_state=22)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "svc = SVC(gamma=.05).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c62026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_metrics import plot_decision_threshold\n",
    "\n",
    "plot_decision_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a312aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc471a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lower_threshold = svc.decision_function(X_test) > -.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lower_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487a7cd6",
   "metadata": {},
   "source": [
    "### Precision-recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840de0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, svc.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96192277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use more data points for a smoother curve\n",
    "X, y = make_blobs(n_samples=(4000, 500), cluster_std=[7.0, 2], random_state=22)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "svc = SVC(gamma=.05).fit(X_train, y_train)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, svc.decision_function(X_test))\n",
    "\n",
    "# find threshold closest to zero\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10, label=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.plot(precision, recall, label=\"precision recall curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82974001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, max_features=2)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# RandomForestClassifier has predict_proba, but not decision_function\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.plot(precision, recall, label=\"svc\")\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10,label=\"threshold zero svc\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.plot(precision_rf, recall_rf, label=\"rf\")\n",
    "\n",
    "close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "plt.plot(precision_rf[close_default_rf], recall_rf[close_default_rf], '^', c='k', markersize=10, label=\"threshold 0.5 rf\", fillstyle=\"none\", mew=2)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"f1_score of random forest: {f1_score(y_test, rf.predict(X_test)):.3f}\")\n",
    "print(f\"f1_score of svc: {f1_score(y_test, svc.predict(X_test)):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b871ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "ap_rf = average_precision_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "ap_svc = average_precision_score(y_test, svc.decision_function(X_test))\n",
    "\n",
    "print(f\"Average precision of random forest: {ap_rf:.3f}\")\n",
    "print(f\"Average precision of svc: {ap_svc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3721a9",
   "metadata": {},
   "source": [
    "### Receiver operating characteristics (ROC) and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893501da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, svc.decision_function(X_test))\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "# find threshold closest to zero\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10, label=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve SVC\")\n",
    "plt.plot(fpr_rf, tpr_rf, label=\"ROC Curve RF\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10, label=\"threshold zero SVC\", fillstyle=\"none\", c='k', mew=2)\n",
    "\n",
    "close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "\n",
    "plt.plot(fpr_rf[close_default_rf], tpr[close_default_rf], '^', markersize=10, label=\"threshold 0.5 RF\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rf_auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "svc_auc = roc_auc_score(y_test, svc.decision_function(X_test))\n",
    "\n",
    "print(f\"AUC for Random Forest: {rf_auc:.3f}\")\n",
    "print(f\"AUC for SVC: {svc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5541e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = digits.target == 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=0)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for gamma in [1, 0.05, 0.01]:\n",
    "    svc = SVC(gamma=gamma).fit(X_train, y_train)\n",
    "    accuracy = svc.score(X_test, y_test)\n",
    "    auc = roc_auc_score(y_test, svc.decision_function(X_test))\n",
    "    fpr, tpr, _ = roc_curve(y_test , svc.decision_function(X_test))\n",
    "    print(f\"gamma = {gamma:.2f} accuracy = {accuracy:.2f} AUC = {auc:.2f}\")\n",
    "    plt.plot(fpr, tpr, label=\"gamma={:.3f}\".format(gamma))\n",
    "\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.xlim(-0.01, 1)\n",
    "plt.ylim(0, 1.02)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd03b7",
   "metadata": {},
   "source": [
    "## Metrics for Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1824c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, solver=\"liblinear\").fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred):.3f}\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(y_test, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10dab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.tools import heatmap\n",
    "\n",
    "scores_image = heatmap(confusion_matrix(y_test, pred), \n",
    "                       xlabel='Predicted label', \n",
    "                       ylabel='True label', \n",
    "                       xticklabels=digits.target_names, \n",
    "                       yticklabels=digits.target_names, \n",
    "                       cmap=plt.cm.gray_r, \n",
    "                       fmt=\"%d\")\n",
    "\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c414a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f01115",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Micro average f1 score: {f1_score(y_test, pred, average='micro'):.3f}\")\n",
    "print(f\"Macro average f1 score: {f1_score(y_test, pred, average='macro'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac7480",
   "metadata": {},
   "source": [
    "## Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a71488",
   "metadata": {},
   "source": [
    "## Using Evaluation Metrics in Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89cce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# default scoring for classification is accuracy\n",
    "print(f\"Default scoring: {cross_val_score(SVC(), digits.data, digits.target == 9, cv=3)}\")\n",
    "\n",
    "# providing scoring=\"accuracy\" doesn't change the results\n",
    "explicit_accuracy = cross_val_score(SVC(), digits.data, digits.target == 9, scoring=\"accuracy\", cv=3)\n",
    "print(f\"Explicit accuracy scoring: {explicit_accuracy}\")\n",
    "\n",
    "roc_auc = cross_val_score(SVC(), digits.data, digits.target == 9, scoring=\"roc_auc\", cv=3)\n",
    "print(f\"AUC scoring: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97cfc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target == 9, random_state=0)\n",
    "\n",
    "# we provide a somewhat bad grid to illustrate the point:\n",
    "param_grid = {'gamma': [0.0001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# using the default scoring of accuracy:\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Grid-Search with accuracy\")\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(f\"Best cross-validation score (accuracy)): {grid.best_score_:.3f}\")\n",
    "print(f\"Test set AUC: {roc_auc_score(y_test, grid.decision_function(X_test)):.3f}\")\n",
    "print(f\"Test set accuracy: {grid.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using AUC scoring instead:\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, scoring=\"roc_auc\")\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"\\nGrid-Search with AUC\")\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(f\"Best cross-validation score (AUC): {grid.best_score_:.3f}\")\n",
    "print(f\"Test set AUC: {roc_auc_score(y_test, grid.decision_function(X_test)):.3f}\")\n",
    "print(f\"Test set accuracy: {grid.score(X_test, y_test):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
