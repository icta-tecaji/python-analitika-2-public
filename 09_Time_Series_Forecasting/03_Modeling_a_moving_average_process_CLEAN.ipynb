{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ac743a",
   "metadata": {},
   "source": [
    "# Modeling a moving average process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094adee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925c150c",
   "metadata": {},
   "source": [
    "When performing statistical modeling, we need to perform hypothesis\n",
    "testing, study our data carefully to extract its properties, and find the best model\n",
    "for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1869d4",
   "metadata": {},
   "source": [
    "Models:\n",
    "- `MA(q)` models\n",
    "- `AR(p)` models\n",
    "- `ARMA(p,q)` models\n",
    "- `RIMA(p,d,q)` models for non-stationary time series\n",
    "- `SARIMA(p,d,q)(P,D,Q)` for seasonal time series\n",
    "- `SARIMAX` models to include external variables in your forecast\n",
    "- `VAR(p)` model for predicting many time series at once\n",
    "- `exponential smoothing` basically takes a weighted average of past values to predict future values. The general idea behind exponential smoothing is that past values are less important than more recent values when predicting the future, so they are assigned a smaller weight.\n",
    "- There are also statistical approaches to modeling time series with different seasonal periods, such as the `BATS` and `TBATS` models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5587b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/widget_sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11bd635",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['widget_sales'])\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Widget sales (k$)')\n",
    "\n",
    "plt.xticks(\n",
    "    [0, 30, 57, 87, 116, 145, 175, 204, 234, 264, 293, 323, 352, 382, 409, 439, 468, 498], \n",
    "    ['Jan 2019', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Jan 2020', 'Feb', 'Mar', 'Apr', 'May', 'Jun'])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021fc4fd",
   "metadata": {},
   "source": [
    "## Defining a moving average process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f7d99",
   "metadata": {},
   "source": [
    "A **moving average process, or the moving average (MA) model**, states that the current\n",
    "value is **linearly dependent on the current and past error terms**. The error terms are\n",
    "assumed to be mutually independent and normally distributed, just like white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951661c7",
   "metadata": {},
   "source": [
    "1. As usual, the first step is to gather the data. \n",
    "2. Then we test for stationarity. \n",
    "    - If our series is not stationary, we apply transformations, such as differencing, until the series is stationary. \n",
    "3. Then we plot the ACF and look for significant autocorrelation coefficients.\n",
    "    - In the case of a random walk, we will not see significant coefficients after lag 0.\n",
    "4. On the other hand, if we see significant coefficients, we must check whether they become abruptly non-significant after some lag q. If that is the case, then we know that we have a moving average process of order q. Otherwise, we must follow a different set of steps to discover the underlying process of our time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa7d0b",
   "metadata": {},
   "source": [
    "<img src=\"images/tsf_03.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d240720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "ADF_result = adfuller(df['widget_sales'])\n",
    "\n",
    "print(f'ADF Statistic: {ADF_result[0]}')\n",
    "print(f'p-value: {ADF_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5369d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_sales_diff = np.diff(df['widget_sales'], n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a29f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(widget_sales_diff)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Widget sales - diff (k$)')\n",
    "\n",
    "plt.xticks(\n",
    "    [0, 30, 57, 87, 116, 145, 175, 204, 234, 264, 293, 323, 352, 382, 409, 439, 468, 498], \n",
    "    ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', '2020', 'Feb', 'Mar', 'Apr', 'May', 'Jun'])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF_result = adfuller(widget_sales_diff)\n",
    "\n",
    "print(f'ADF Statistic: {ADF_result[0]}')\n",
    "print(f'p-value: {ADF_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(widget_sales_diff, lags=30);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d98a60",
   "metadata": {},
   "source": [
    "## Forecasting a moving average process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937cb682",
   "metadata": {},
   "source": [
    "The **moving average model assumes stationarity, meaning that our forecasts must\n",
    "be done on a stationary time series.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = pd.DataFrame({'widget_sales_diff': widget_sales_diff})\n",
    "\n",
    "train = df_diff[:int(0.9*len(df_diff))]\n",
    "test = df_diff[int(0.9*len(df_diff)):]\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "\n",
    "ax1.plot(df['widget_sales'])\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Widget sales (k$)')\n",
    "ax1.axvspan(450, 500, color='#808080', alpha=0.2)\n",
    "\n",
    "ax2.plot(df_diff['widget_sales_diff'])\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Widget sales - diff (k$)')\n",
    "ax2.axvspan(449, 498, color='#808080', alpha=0.2)\n",
    "\n",
    "plt.xticks(\n",
    "    [0, 30, 57, 87, 116, 145, 175, 204, 234, 264, 293, 323, 352, 382, 409, 439, 468, 498], \n",
    "    ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', '2020', 'Feb', 'Mar', 'Apr', 'May', 'Jun'])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "def rolling_forecast(df: pd.DataFrame, train_len: int, horizon: int, window: int, method: str) -> list:\n",
    "    \"\"\"\n",
    "    - The horizon parameter is equal to the length of the test set and represents how\n",
    "many values must be predicted.\n",
    "    - train_len parameter initializes the number of data points that can be\n",
    "used to fit a model.\n",
    "    - window parameter specifies how many timesteps are predicted at a time.\n",
    "    - method parameter specifies what model to use.\n",
    "    \"\"\"\n",
    "    total_len = train_len + horizon\n",
    "    \n",
    "    if method == 'mean':\n",
    "        pred_mean = []\n",
    "        \n",
    "        for i in range(train_len, total_len, window):\n",
    "            mean = np.mean(df[:i].values)\n",
    "            pred_mean.extend(mean for _ in range(window))\n",
    "\n",
    "        return pred_mean\n",
    "\n",
    "    elif method == 'last':\n",
    "        pred_last_value = []\n",
    "        \n",
    "        for i in range(train_len, total_len, window):\n",
    "            last_value = df[:i].iloc[-1].values[0]\n",
    "            pred_last_value.extend(last_value for _ in range(window))\n",
    "            \n",
    "        return pred_last_value\n",
    "    \n",
    "    elif method == 'MA':\n",
    "        pred_MA = []\n",
    "        \n",
    "        for i in range(train_len, total_len, window):\n",
    "            model = SARIMAX(df[:i], order=(0,0,2))\n",
    "            res = model.fit(disp=False)\n",
    "            predictions = res.get_prediction(0, i + window - 1)\n",
    "            oos_pred = predictions.predicted_mean.iloc[-window:]\n",
    "            pred_MA.extend(oos_pred)\n",
    "            \n",
    "        return pred_MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = test.copy()\n",
    "\n",
    "TRAIN_LEN = len(train)\n",
    "HORIZON = len(test)\n",
    "WINDOW = 2\n",
    "\n",
    "pred_mean = rolling_forecast(df_diff, TRAIN_LEN, HORIZON, WINDOW, 'mean')\n",
    "pred_last_value = rolling_forecast(df_diff, TRAIN_LEN, HORIZON, WINDOW, 'last')\n",
    "pred_MA = rolling_forecast(df_diff, TRAIN_LEN, HORIZON, WINDOW, 'MA')\n",
    "\n",
    "pred_df['pred_mean'] = pred_mean\n",
    "pred_df['pred_last_value'] = pred_last_value\n",
    "pred_df['pred_MA'] = pred_MA\n",
    "\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cdb94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df_diff['widget_sales_diff'])\n",
    "ax.plot(pred_df['widget_sales_diff'], 'b-', label='actual')\n",
    "ax.plot(pred_df['pred_mean'], 'g:', label='mean')\n",
    "ax.plot(pred_df['pred_last_value'], 'r-.', label='last')\n",
    "ax.plot(pred_df['pred_MA'], 'k--', label='MA(2)')\n",
    "\n",
    "ax.legend(loc=2)\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Widget sales - diff (k$)')\n",
    "\n",
    "ax.axvspan(449, 498, color='#808080', alpha=0.2)\n",
    "\n",
    "ax.set_xlim(430, 500)\n",
    "\n",
    "plt.xticks(\n",
    "    [439, 468, 498], \n",
    "    ['Apr', 'May', 'Jun'])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_mean = mean_squared_error(pred_df['widget_sales_diff'], pred_df['pred_mean'])\n",
    "mse_last = mean_squared_error(pred_df['widget_sales_diff'], pred_df['pred_last_value'])\n",
    "mse_MA = mean_squared_error(pred_df['widget_sales_diff'], pred_df['pred_MA'])\n",
    "\n",
    "print(mse_mean, mse_last, mse_MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c195f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = ['mean', 'last_value', 'MA(2)']\n",
    "y = [mse_mean, mse_last, mse_MA]\n",
    "\n",
    "ax.bar(x, y, width=0.4)\n",
    "ax.set_xlabel('Methods')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.set_ylim(0, 5)\n",
    "\n",
    "for index, value in enumerate(y):\n",
    "    plt.text(x=index, y=value+0.25, s=str(round(value, 2)), ha='center')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred_widget_sales'] = pd.Series(dtype=\"float64\")\n",
    "df['pred_widget_sales'][450:] = df['widget_sales'].iloc[450] + pred_df['pred_MA'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceace85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['widget_sales'], 'b-', label='actual')\n",
    "ax.plot(df['pred_widget_sales'], 'k--', label='MA(2)')\n",
    "\n",
    "ax.legend(loc=2)\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Widget sales (K$)')\n",
    "\n",
    "ax.axvspan(450, 500, color='#808080', alpha=0.2)\n",
    "\n",
    "ax.set_xlim(400, 500)\n",
    "\n",
    "plt.xticks(\n",
    "    [409, 439, 468, 498], \n",
    "    ['Mar', 'Apr', 'May', 'Jun'])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4061d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae_MA_undiff = mean_absolute_error(df['widget_sales'].iloc[450:], df['pred_widget_sales'].iloc[450:])\n",
    "\n",
    "print(mae_MA_undiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e793c",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06fb37",
   "metadata": {},
   "source": [
    "- A moving average process states that the present value is linearly dependent on\n",
    "the mean, present error term, and past error terms. The error terms are normally\n",
    "distributed.\n",
    "- You can identify the order q of a stationary moving average process by studying\n",
    "the ACF plot. The coefficients are significant up until lag q only.\n",
    "- You can predict up to q steps into the future because the error terms are not\n",
    "observed in the data and must be recursively estimated.\n",
    "- Predicting beyond q steps into the future will simply return the mean of the\n",
    "series. To avoid that, you can apply rolling forecasts.\n",
    "- If you apply a transformation to the data, you must undo it to bring your predictions\n",
    "back to the original scale of the data.\n",
    "- The moving average model assumes the data is stationary. Therefore, you can\n",
    "only use this model on stationary data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
