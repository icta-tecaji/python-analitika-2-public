{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f811a7",
   "metadata": {},
   "source": [
    "# Modeling complex time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebca2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b385f1",
   "metadata": {},
   "source": [
    "## Forecasting bandwidth usage for data centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bandwidth.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79118f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['hourly_bandwidth'])\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Hourly bandwith usage (MBps)')\n",
    "\n",
    "plt.xticks(\n",
    "    np.arange(0, 10000, 730), \n",
    "    ['Jan 2019', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Jan 2020', 'Feb'])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e401b",
   "metadata": {},
   "source": [
    "## Examining the autoregressive moving average process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58838f78",
   "metadata": {},
   "source": [
    "**The autoregressive moving average process is a combination of the autoregressive process\n",
    "and the moving average process.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a119651",
   "metadata": {},
   "source": [
    "## Identifying a stationary ARMA process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4133d",
   "metadata": {},
   "source": [
    "**If neither of the ACF and PACF plots shows a clear cutoff\n",
    "between significant and non-significant coefficients, then we have an ARMA(p,q)\n",
    "process.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e0924",
   "metadata": {},
   "source": [
    "<img src=\"images/tsf_05.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e943658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "ar1 = np.array([1, -0.33])\n",
    "ma1 = np.array([1, 0.9])\n",
    "\n",
    "ARMA_1_1 = ArmaProcess(ar1, ma1).generate_sample(nsample=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82610c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "ADF_result = adfuller(ARMA_1_1)\n",
    "\n",
    "print(f'ADF Statistic: {ADF_result[0]}')\n",
    "print(f'p-value: {ADF_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "plot_acf(ARMA_1_1, lags=20);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(ARMA_1_1, lags=20, method='ywm');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb918634",
   "metadata": {},
   "source": [
    "> If your process is stationary and both the ACF and PACF plots show a decaying or sinusoidal\n",
    "pattern, then it is a stationary ARMA(p,q) process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979bce36",
   "metadata": {},
   "source": [
    "## Devising a general modeling procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5229d6e8",
   "metadata": {},
   "source": [
    "<img src=\"images/tsf_06.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc27c8e",
   "metadata": {},
   "source": [
    "General modeling procedure for an ARMA(p,q) process: \n",
    "1. The first steps are to gather the data, test for stationarity, and apply transformations accordingly. \n",
    "2. Then we define a list of possible values for p and q. \n",
    "3. We then fit every combination of ARMA(p,q) to our data and select the model with the lowest AIC. \n",
    "4. Then we perform the residual analysis by looking at the Q-Q plot and the residual correlogram. \n",
    "5. If they approach that of white noise, the model can be used for forecasts. Otherwise, we must try different values for p and q."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff455f",
   "metadata": {},
   "source": [
    "## Understanding the Akaike information criterion (AIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9c731",
   "metadata": {},
   "source": [
    "**The AIC estimates the quality of a model relative to other models.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501fbfa5",
   "metadata": {},
   "source": [
    "**The lower the value of the AIC, the better the model.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "ps = range(0, 4, 1)\n",
    "qs = range(0, 4, 1)\n",
    "\n",
    "order_list = list(product(ps, qs))\n",
    "print(order_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383cf2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from typing import Union\n",
    "\n",
    "def optimize_ARMA(endog: Union[pd.Series, list], order_list: list) -> pd.DataFrame:\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for order in tqdm(order_list):\n",
    "        try: \n",
    "            model = SARIMAX(endog, order=(order[0], 0, order[1]), simple_differencing=False).fit(disp=False)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        aic = model.aic\n",
    "        results.append([order, aic])\n",
    "        \n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.columns = ['(p,q)', 'AIC']\n",
    "    \n",
    "    #Sort in ascending order, lower AIC is better\n",
    "    result_df = result_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = optimize_ARMA(ARMA_1_1, order_list)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d59f2e7",
   "metadata": {},
   "source": [
    "## Understanding residual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4ab52",
   "metadata": {},
   "source": [
    "We **must measure its\n",
    "absolute quality by performing an analysis on the model’s residuals.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b7fa6",
   "metadata": {},
   "source": [
    "Does:\n",
    "1. the Q-Q plot show a straight line, and\n",
    "2. are the residuals uncorrelated? \n",
    "\n",
    "If the answer to both questions is yes, then we have a\n",
    "model that’s ready to make forecasts. Otherwise, we must try different combinations\n",
    "of (p,q) and restart the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919eb21",
   "metadata": {},
   "source": [
    "**A Q-Q plot is a plot of the quantiles of two distributions against each other. In time\n",
    "series forecasting, we plot the distribution of our residuals on the y-axis against the\n",
    "theoretical normal distribution on the x-axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f7bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "gamma = np.random.default_rng().standard_gamma(shape=2, size=1000)\n",
    "qqplot(gamma, line='45');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f42af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = np.random.normal(size=1000)\n",
    "qqplot(normal, line='45');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35421317",
   "metadata": {},
   "source": [
    "## Performing residual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60fec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(ARMA_1_1, order=(1,0,1), simple_differencing=False)\n",
    "model_fit = model.fit(disp=False)\n",
    "residuals = model_fit.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1956b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "qqplot(residuals, line='45');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.plot_diagnostics(figsize=(10, 8));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67eea9",
   "metadata": {},
   "source": [
    "We will use the `acorr_ljungbox` function from statsmodels to perform the Ljung-Box test on the\n",
    "residuals. T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "res = acorr_ljungbox(residuals, np.arange(1, 11, 1))\n",
    "\n",
    "print(list(res[\"lb_pvalue\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd292cc7",
   "metadata": {},
   "source": [
    "The resulting list of p-values shows that each is above 0.05. Therefore, at each lag, the\n",
    "null hypothesis cannot be rejected, **meaning that the residuals are independently distributed\n",
    "and uncorrelated.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961439a7",
   "metadata": {},
   "source": [
    "## Applying the general modeling procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b98d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bandwidth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['hourly_bandwidth'])\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Hourly bandwith usage (MBps)')\n",
    "\n",
    "plt.xticks(\n",
    "    np.arange(0, 10000, 730), \n",
    "    ['Jan 2019', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Jan 2020', 'Feb'])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3895a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "ADF_result = adfuller(df['hourly_bandwidth'])\n",
    "\n",
    "print(f'ADF Statistic: {ADF_result[0]}')\n",
    "print(f'p-value: {ADF_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e958002",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth_diff = np.diff(df.hourly_bandwidth, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f80129",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF_result = adfuller(bandwidth_diff)\n",
    "\n",
    "print(f'ADF Statistic: {ADF_result[0]}')\n",
    "print(f'p-value: {ADF_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = pd.DataFrame({'bandwidth_diff': bandwidth_diff})\n",
    "\n",
    "train = df_diff[:-168]\n",
    "test = df_diff[-168:]\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51879b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "ax1.plot(df['hourly_bandwidth'])\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Hourly bandwidth usage (MBps)')\n",
    "ax1.axvspan(9831, 10000, color='#808080', alpha=0.2)\n",
    "\n",
    "ax2.plot(df_diff['bandwidth_diff'])\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Hourly bandwidth - diff (MBps)')\n",
    "ax2.axvspan(9830, 9999, color='#808080', alpha=0.2)\n",
    "\n",
    "plt.xticks(\n",
    "    np.arange(0, 10000, 730), \n",
    "    ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', '2020', 'Feb'])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1404c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def optimize_ARMA(endog: Union[pd.Series, list], order_list: list) -> pd.DataFrame:\n",
    "    results = []\n",
    "    for order in tqdm(order_list):\n",
    "        try: \n",
    "            model = SARIMAX(endog, order=(order[0], 0, order[1]), simple_differencing=False).fit(disp=False)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        aic = model.aic\n",
    "        results.append([order, aic])\n",
    "        \n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.columns = ['(p,q)', 'AIC']\n",
    "    \n",
    "    #Sort in ascending order, lower AIC is better\n",
    "    result_df = result_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = range(0, 4, 1)\n",
    "qs = range(0, 4, 1)\n",
    "\n",
    "order_list = list(product(ps, qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fdca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = optimize_ARMA(train['bandwidth_diff'], order_list)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c13a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train['bandwidth_diff'], order=(2,0,2), simple_differencing=False)\n",
    "model_fit = model.fit(disp=False)\n",
    "model_fit.plot_diagnostics(figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf4c4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = model_fit.resid\n",
    "res = acorr_ljungbox(residuals, np.arange(1, 11, 1))\n",
    "\n",
    "print(list(res[\"lb_pvalue\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cea014",
   "metadata": {},
   "source": [
    "## Forecasting bandwidth usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe3c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_forecast(df: pd.DataFrame, train_len: int, horizon: int, window: int, method: str) -> list:\n",
    "    \n",
    "    total_len = train_len + horizon\n",
    "    end_idx = train_len\n",
    "    \n",
    "    if method == 'mean':\n",
    "        pred_mean = []\n",
    "        \n",
    "        for i in range(train_len, total_len, window):\n",
    "            mean = np.mean(df[:i].values)\n",
    "            pred_mean.extend(mean for _ in range(window))\n",
    "            \n",
    "        return pred_mean\n",
    "\n",
    "    elif method == 'last':\n",
    "        pred_last_value = []\n",
    "        \n",
    "        for i in range(train_len, total_len, window):\n",
    "            last_value = df[:i].iloc[-1].values[0]\n",
    "            pred_last_value.extend(last_value for _ in range(window))\n",
    "            \n",
    "        return pred_last_value\n",
    "    \n",
    "    elif method == 'ARMA':\n",
    "        pred_ARMA = []\n",
    "        \n",
    "        for i in range(train_len, total_len, window):\n",
    "            model = SARIMAX(df[:i], order=(2,0,2))\n",
    "            res = model.fit(disp=False)\n",
    "            predictions = res.get_prediction(0, i + window - 1)\n",
    "            oos_pred = predictions.predicted_mean.iloc[-window:]\n",
    "            pred_ARMA.extend(oos_pred)\n",
    "            \n",
    "        return pred_ARMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53897242",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LEN = len(train)\n",
    "HORIZON = len(test)\n",
    "WINDOW = 2\n",
    "\n",
    "pred_mean = rolling_forecast(df_diff, TRAIN_LEN, HORIZON, WINDOW, 'mean')\n",
    "pred_last_value = rolling_forecast(df_diff, TRAIN_LEN, HORIZON, WINDOW, 'last')\n",
    "pred_ARMA = rolling_forecast(df_diff, TRAIN_LEN, HORIZON, WINDOW, 'ARMA')\n",
    "\n",
    "test.loc[:, 'pred_mean'] = pred_mean\n",
    "test.loc[:, 'pred_last_value'] = pred_last_value\n",
    "test.loc[:, 'pred_ARMA'] = pred_ARMA\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ded0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df_diff['bandwidth_diff'])\n",
    "ax.plot(test['bandwidth_diff'], 'b-', label='actual')\n",
    "ax.plot(test['pred_mean'], 'g:', label='mean')\n",
    "ax.plot(test['pred_last_value'], 'r-.', label='last')\n",
    "ax.plot(test['pred_ARMA'], 'k--', label='ARMA(2,2)')\n",
    "\n",
    "ax.legend(loc=2)\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Hourly bandwidth - diff (MBps)')\n",
    "\n",
    "ax.axvspan(9830, 9999, color='#808080', alpha=0.2)\n",
    "\n",
    "ax.set_xlim(9800, 9999)\n",
    "\n",
    "plt.xticks(\n",
    "    [9802, 9850, 9898, 9946, 9994],\n",
    "    ['2020-02-13', '2020-02-15', '2020-02-17', '2020-02-19', '2020-02-21'])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5118375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_mean = mean_squared_error(test['bandwidth_diff'], test['pred_mean'])\n",
    "mse_last = mean_squared_error(test['bandwidth_diff'], test['pred_last_value'])\n",
    "mse_ARMA = mean_squared_error(test['bandwidth_diff'], test['pred_ARMA'])\n",
    "\n",
    "print(mse_mean, mse_last, mse_ARMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred_bandwidth'] = pd.Series(dtype=\"float\")\n",
    "df['pred_bandwidth'][9832:] = df['hourly_bandwidth'].iloc[9832] + test['pred_ARMA'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f35796",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['hourly_bandwidth'])\n",
    "ax.plot(df['hourly_bandwidth'], 'b-', label='actual')\n",
    "ax.plot(df['pred_bandwidth'], 'k--', label='ARMA(2,2)')\n",
    "\n",
    "ax.legend(loc=2)\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Hourly bandwith usage (MBps)')\n",
    "\n",
    "ax.axvspan(9831, 10000, color='#808080', alpha=0.2)\n",
    "\n",
    "ax.set_xlim(9800, 9999)\n",
    "\n",
    "plt.xticks(\n",
    "    [9802, 9850, 9898, 9946, 9994],\n",
    "    ['2020-02-13', '2020-02-15', '2020-02-17', '2020-02-19', '2020-02-21'])\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21fc935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae_ARMA_undiff = mean_absolute_error(df['hourly_bandwidth'][9832:], df['pred_bandwidth'][9832:])\n",
    "\n",
    "print(mae_ARMA_undiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df612d",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fefe6e",
   "metadata": {},
   "source": [
    "- The autoregressive moving average model, denoted as `ARMA(p,q)`, is the combination of the autoregressive model `AR(p)` and the moving average model `MA(q)`.\n",
    "- An ARMA(p,q) process **will display a decaying pattern or a sinusoidal pattern on both the ACF and PACF plots.** Therefore, they cannot be used to estimate the orders p and q.\n",
    "- The general modeling procedure does not rely on the ACF and PACF plots. Instead, we fit many ARMA(p,q) models and perform **model selection and residual analysis.**\n",
    "- Model selection is done with the Akaike information criterion (AIC). It quantifies the information loss of a model, and it is related to the number of parameters in a model and its goodness of fit. The lower the AIC, the better the model.\n",
    "- The AIC is relative measure of quality. It returns the best model among other models. For an absolute measure of quality, we perform residual analysis.\n",
    "- Residuals of a good model must approximate white noise, meaning that they must be uncorrelated, normally distributed, and independent.\n",
    "- The Q-Q plot is a graphical tool for comparing two distributions. We use it to compare the distribution of the residuals against a theoretical normal distribution. If the plot shows a straight line that lies on y = x, then both distributions are similar. Otherwise, it means that the residuals are not normally distributed.\n",
    "- The Ljung-Box test allows us to determine whether the residuals are correlated or not. The null hypothesis states that the data is independently distributed and uncorrelated. If the returned p-values are larger than 0.05, we cannot reject the null hypothesis, meaning that the residuals are uncorrelated, just like white noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
