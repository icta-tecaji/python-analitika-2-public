{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68b0f58",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dba727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfbfee7",
   "metadata": {},
   "source": [
    "<img src=\"./images/decision_tree.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5c04d",
   "metadata": {},
   "source": [
    "<img src=\"./images/dt_01.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94e00d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fe8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51534365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f6958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c11db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea2201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17641a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0192035",
   "metadata": {},
   "source": [
    "## Building decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bde04a",
   "metadata": {},
   "source": [
    "<img src=\"./images/two_moons.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc95202",
   "metadata": {},
   "source": [
    "<img src=\"./images/depth_1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189b5d3",
   "metadata": {},
   "source": [
    "<img src=\"./images/depth_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57c19d",
   "metadata": {},
   "source": [
    "<img src=\"./images/depth_9.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72241f8a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import helpers_tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "        \n",
    "fig, ax = plt.subplots(1, 4, figsize=(16, 3))\n",
    "fig.subplots_adjust(left=0.02, right=0.98, wspace=0.1)\n",
    "\n",
    "X, y = make_blobs(n_samples=300, centers=4, random_state=0, cluster_std=1.0)\n",
    "\n",
    "for axi, depth in zip(ax, range(1, 5)):\n",
    "    model = DecisionTreeClassifier(max_depth=depth)\n",
    "    helpers_tree.visualize_tree(model, X, y, ax=axi)\n",
    "    axi.set_title(f'depth = {depth}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ec5bd",
   "metadata": {},
   "source": [
    "## Measuring purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0f43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "126e84c1-8dc5-4c3b-beb8-e9b5e5cfaf91",
   "metadata": {},
   "source": [
    "<img src=\"./images/dt_06.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0f65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f4a0c47",
   "metadata": {},
   "source": [
    "<img src=\"./images/dt_08.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc9f735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e49c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d754f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72606a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd76159",
   "metadata": {},
   "source": [
    "## Build a decision tree model using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32365ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=300, centers=4, random_state=0, cluster_std=1.0)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e54267d",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b9ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import helpers_tree\n",
    "\n",
    "helpers_tree.plot_tree_interactive(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d17c1c",
   "metadata": {},
   "source": [
    "## Controlling complexity of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9a6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import helpers_tree\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "helpers_tree.visualize_tree(model, X[::2], y[::2], boundaries=False, ax=ax[0])\n",
    "helpers_tree.visualize_tree(model, X[1::2], y[1::2], boundaries=False, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176d032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163becf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199be54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b428bec",
   "metadata": {},
   "source": [
    "- `max_depth`: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than `min_samples_split` samples.\n",
    "- `min_samples_split`: The minimum number of samples required to split an internal node.\n",
    "- `min_impurity_decrease`: A node will be split if this split induces a decrease of the impurity greater than or equal to this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c72da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy on training set: {tree.score(X_train, y_train):.3f}\")\n",
    "print(f\"Accuracy on test set: {tree.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf795e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79681704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951b523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy on training set: {tree.score(X_train, y_train):.3f}\")\n",
    "print(f\"Accuracy on test set: {tree.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f806396",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bce398",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_scores = {}\n",
    "testing_scores = {}\n",
    "\n",
    "depths = list(range(1,10))\n",
    "\n",
    "for depth in depths:\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, random_state=0)\n",
    "    tree.fit(X_train, y_train)\n",
    "    traning_scores[depth] = tree.score(X_train, y_train)\n",
    "    testing_scores[depth] = tree.score(X_test, y_test)\n",
    "    \n",
    "plt.plot(traning_scores.keys(), traning_scores.values(), c=\"blue\", label=\"training\")\n",
    "plt.plot(testing_scores.keys(), testing_scores.values(), c=\"red\", label=\"testing\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7addcac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_scores = {}\n",
    "testing_scores = {}\n",
    "\n",
    "min_samples_splits = list(range(2,60))\n",
    "\n",
    "for mss in min_samples_splits:\n",
    "    tree = DecisionTreeClassifier(min_samples_split=mss, random_state=0)\n",
    "    tree.fit(X_train, y_train)\n",
    "    traning_scores[mss] = tree.score(X_train, y_train)\n",
    "    testing_scores[mss] = tree.score(X_test, y_test)\n",
    "    \n",
    "plt.plot(traning_scores.keys(), traning_scores.values(), c=\"blue\", label=\"training\")\n",
    "plt.plot(testing_scores.keys(), testing_scores.values(), c=\"red\", label=\"testing\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045b946",
   "metadata": {},
   "source": [
    "## Analyzing decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1093f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "export_graphviz(tree, out_file=\"data/tree.dot\", \n",
    "                class_names=[\"malignant\", \"benign\"], \n",
    "                feature_names=cancer.feature_names, \n",
    "                impurity=False, \n",
    "                filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c48700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "with open(\"data/tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709748b",
   "metadata": {},
   "source": [
    "## Feature importance in trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21971206",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008902b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances_cancer(model):\n",
    "    plt.figure(figsize=(5, 7))\n",
    "    n_features = cancer.data.shape[1]\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), cancer.feature_names)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importances_cancer(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9c16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40145b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8013e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1367e251",
   "metadata": {},
   "source": [
    "## Example: Heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "heart_data = pd.read_csv('data/heart.csv')\n",
    "# show the first 5 lines of the dataframe\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_data.drop('HeartDisease', axis=1)\n",
    "y = heart_data['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b350ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46193125",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec93beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f62c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth=2)\n",
    "dtree.fit(X_train, y_train)\n",
    "predicitions = dtree.predict(X_test)\n",
    "acc = accuracy_score(y_test, predicitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4cd355",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "for criterion in \"gini\", \"entropy\":\n",
    "    for max_depth in [2,3,4,5,6]:\n",
    "        for min_samples_leaf in [5, 10, 20, 30]:\n",
    "            dtree = DecisionTreeClassifier(max_depth=max_depth, \n",
    "                                           criterion=criterion, \n",
    "                                           min_samples_leaf=min_samples_leaf, \n",
    "                                           random_state=0)\n",
    "            dtree.fit(X_train, y_train)\n",
    "            predicitions = dtree.predict(X_test)\n",
    "            acc = accuracy_score(y_test, predicitions)\n",
    "            if acc > best_acc:\n",
    "                best_params = f\"criterion: {criterion}, max_depth: {max_depth}, min_samples_leaf: {min_samples_leaf}\"\n",
    "                best_acc = acc\n",
    "                \n",
    "print(best_params)\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff4ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=((25,20)))\n",
    "plot_tree(dtree,\n",
    "            feature_names = X.columns,\n",
    "            class_names=['no heart disease', 'heart disease'], \n",
    "            impurity=True,\n",
    "            proportion=True,\n",
    "            filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9dfd6",
   "metadata": {},
   "source": [
    "## Decision trees for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "ram_prices = pd.read_csv(\"data/ram_price.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ram_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(ram_prices[\"date\"], ram_prices[\"price\"])\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Price in $/Mbyte\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f73b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# use historical data to forecast prices after the year 2000\n",
    "data_train = ram_prices[ram_prices[\"date\"] < 2000]\n",
    "data_test = ram_prices[ram_prices[\"date\"] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe1f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict prices based on date\n",
    "X_train = data_train[\"date\"].values.reshape(data_train.shape[0] , 1)\n",
    "\n",
    "# we use a log-transform to get a simpler relationship of data to target\n",
    "y_train = np.log(data_train[\"price\"])\n",
    "\n",
    "tree = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "linear_reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f51e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on all data\n",
    "X_all = ram_prices[\"date\"].values.reshape(ram_prices.shape[0], 1)\n",
    "\n",
    "pred_tree = tree.predict(X_all)\n",
    "pred_lr = linear_reg.predict(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1eaf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# undo log-transform\n",
    "price_tree = np.exp(pred_tree)\n",
    "price_lr = np.exp(pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae64aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(data_train.date, data_train.price, label=\"Training data\")\n",
    "plt.semilogy(data_test.date, data_test.price, label=\"Test data\")\n",
    "plt.semilogy(ram_prices.date, price_tree, label=\"Tree prediction\")\n",
    "plt.semilogy(ram_prices.date, price_lr, label=\"Linear prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898a7d28",
   "metadata": {},
   "source": [
    " **The tree has no ability to generate “new” responses, outside of what was seen in the training\n",
    "data**. This shortcoming **applies to all models based on trees**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add999e5",
   "metadata": {},
   "source": [
    "## Strengths, weaknesses, and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ac81d",
   "metadata": {},
   "source": [
    "As discussed earlier, the **parameters that control model complexity in decision trees**\n",
    "are the pre-pruning parameters that stop the building of the tree before it is fully\n",
    "developed. Usually, picking one of the pre-pruning strategies—setting either\n",
    "`max_depth`, `max_leaf_nodes`, or `min_samples_leaf` is sufficient to prevent overfitting.\n",
    "\n",
    "**Decision trees have two advantages** over many of the algorithms we’ve discussed so\n",
    "far: \n",
    "- the resulting model can easily be visualized and understood by nonexperts (at least for smaller trees), \n",
    "- and the algorithms are completely invariant to scaling of the data.  As each feature is processed separately, and the possible splits of the data don’t depend on scaling, no preprocessing like normalization or standardization of features is needed for decision tree algorithms. \n",
    "\n",
    "In particular, **decision trees work well** when you have **features that are on completely different scales**, or a **mix of binary and continuous features.**\n",
    "\n",
    "The **main downside of decision trees** is:\n",
    "- that even with the use of pre-pruning, they tend to overfit and provide poor generalization performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
