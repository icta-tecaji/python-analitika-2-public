{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9f3809",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b09d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712dc183",
   "metadata": {},
   "source": [
    "However, they tend to be **even faster in training**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe04fd30",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666bf44",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5871db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(100, 2, centers=2, random_state=2, cluster_std=1.5)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')\n",
    "ax.set_title('Naive Bayes Model', size=14)\n",
    "\n",
    "xlim = (-8, 8)\n",
    "ylim = (-15, 5)\n",
    "\n",
    "xg = np.linspace(xlim[0], xlim[1], 60)\n",
    "yg = np.linspace(ylim[0], ylim[1], 40)\n",
    "xx, yy = np.meshgrid(xg, yg)\n",
    "Xgrid = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "\n",
    "for label, color in enumerate(['red', 'blue']):\n",
    "    mask = (y == label)\n",
    "    mu, std = X[mask].mean(0), X[mask].std(0)\n",
    "    P = np.exp(-0.5 * (Xgrid - mu) ** 2 / std ** 2).prod(1)\n",
    "    Pm = np.ma.masked_array(P, P < 0.03)\n",
    "    ax.pcolorfast(xg, yg, Pm.reshape(xx.shape), alpha=0.5,\n",
    "                  cmap=color.title() + 's')\n",
    "    ax.contour(xx, yy, P.reshape(xx.shape),\n",
    "               levels=[0.01, 0.1, 0.5, 0.9],\n",
    "               colors=color, alpha=0.2)\n",
    "    \n",
    "ax.set(xlim=xlim, ylim=ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651cd2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "Xnew = [-6, -14] + [14, 18] * rng.rand(2000, 2)\n",
    "\n",
    "ynew = model.predict(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43945dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')\n",
    "lim = plt.axis()\n",
    "# plot new data\n",
    "plt.scatter(Xnew[:, 0], Xnew[:, 1], c=ynew, s=20, cmap='RdBu', alpha=0.1)\n",
    "plt.axis(lim);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3beaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "yprob = model.predict_proba(Xnew)\n",
    "yprob[-8:].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de016ca",
   "metadata": {},
   "source": [
    "## Example: Multinomial Naive Bayes - Classifying Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf72170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['talk.religion.misc', 'soc.religion.christian', 'sci.space', 'comp.graphics']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54540b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5688dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e662f",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(train.data)\n",
    "train_data_transorfed = tfidf.transform(train.data)\n",
    "test_data_transorfed = tfidf.transform(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56364c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(train_data_transorfed, train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = mnb.predict(test_data_transorfed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07029c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(test.target, labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels=train.target_names, yticklabels=train.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6425bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(s, train=train, model=mnb, tfidf=tfidf):\n",
    "    s_trasfomed = tfidf.transform([s])\n",
    "    pred = model.predict(s_trasfomed)\n",
    "    return train.target_names[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b82a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_category('sending a payload to the ISS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_category('discussing islam vs atheism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074252e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_category('determining the screen resolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80bea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_category('my gpu card is very expensive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d30f1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3e76b",
   "metadata": {},
   "source": [
    "- MultinomialNB and BernoulliNB have a single parameter, **`alpha`, which controls\n",
    "model complexity**. \n",
    "- The way alpha works is that the algorithm adds to the data alpha many virtual data points that have positive values for all the features. \n",
    "- This results in a “smoothing” of the statistics. \n",
    "- **A large alpha means more smoothing, resulting in less complex models.**\n",
    "- The algorithm’s performance is relatively robust to the setting of alpha, meaning that setting alpha is not critical for good performance. However, tuning it usually improves accuracy somewhat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41f4db",
   "metadata": {},
   "source": [
    "## Strengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d0076",
   "metadata": {},
   "source": [
    "That said, they have several advantages:\n",
    "- They are extremely fast for both training and prediction\n",
    "- They provide straightforward probabilistic prediction\n",
    "- They are often very easily interpretable (the training procedure is easy to understand)\n",
    "- They have very few (if any) tunable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291eb595",
   "metadata": {},
   "source": [
    "These advantages mean a naive Bayesian classifier is often a **good choice as an initial baseline classification**. \n",
    "1. If it performs suitably, then congratulations: you have a very fast, very interpretable classifier for your problem. \n",
    "2. If it does not perform well, then you can begin exploring more sophisticated models, with some baseline knowledge of how well they should perform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e638c409",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers tend to perform especially well in one of the following situations:\n",
    "- When the naive assumptions actually match the data (very rare in practice)\n",
    "- For very well-separated categories, when model complexity is less important\n",
    "- For very high-dimensional data, when model complexity is less important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68aa5c",
   "metadata": {},
   "source": [
    "This means that **clusters in high dimensions tend to be more separated, on average, than clusters in low dimensions**, assuming the new dimensions actually add information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41dbee3",
   "metadata": {},
   "source": [
    "For this reason, simplistic classifiers like naive Bayes tend to work as well or better than more complicated classifiers as the dimensionality grows: **once you have enough data, even a simple model can be very powerful**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a673644",
   "metadata": {},
   "source": [
    "## Weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea88fa",
   "metadata": {},
   "source": [
    "Because naive Bayesian classifiers make such **stringent assumptions about data**, they will generally **not perform as well as a more complicated model**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab71a5a4",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0365cf6",
   "metadata": {},
   "source": [
    "- GaussianNB is mostly used on very high-dimensional data.\n",
    "- BernoulliNB, and MultinomialNB are widely used for sparse count data such as text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
