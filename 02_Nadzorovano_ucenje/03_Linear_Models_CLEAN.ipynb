{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a059870",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f941080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d45390",
   "metadata": {},
   "source": [
    "## Linear models for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3924699",
   "metadata": {},
   "source": [
    "`ŷ = w[0] * x[0] + w[1] * x[1] + ... + w[p] * x[p] + b`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2b36e",
   "metadata": {},
   "source": [
    "`ŷ = w[0] * x[0] + b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37205a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_linear_regression_wave import plot_linear_regression_wave\n",
    "\n",
    "plot_linear_regression_wave()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e698011",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8cc1c8",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*fX95txC9xSwSPeP6ch2nmg.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59295ad3",
   "metadata": {},
   "source": [
    "<img alt=\"Visualizing RSS\" src=\"https://s3.amazonaws.com/dq-content/235/visualizing_rss.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51727a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = helpers.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfc149",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train,y_train, \".\")\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_position('center')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['bottom'].set_position('center')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.set_ylim(-3, 3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lr.coef_: {}\".format(lr.coef_))\n",
    "print(\"lr.intercept_: {}\".format(lr.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set score: {lr.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test set score: {lr.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b9ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.datasets import load_extended_boston\n",
    "\n",
    "X, y = load_extended_boston()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set score: {lr.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test set score: {lr.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182386fc",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85125ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "print(f\"Training set score: {ridge.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test set score: {ridge.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e86b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_scores = {}\n",
    "testing_scores = {}\n",
    "\n",
    "alphas = [0.001, 0.01, 0.1, 1, 5, 10, 20]\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha).fit(X_train, y_train)\n",
    "    traning_scores[alpha] = ridge.score(X_train, y_train)\n",
    "    testing_scores[alpha] = ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(traning_scores.keys(), traning_scores.values(), c=\"blue\", label=\"training\")\n",
    "plt.plot(testing_scores.keys(), testing_scores.values(), c=\"red\", label=\"testing\")\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "print(f\"Training set score: {ridge10.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test set score: {ridge10.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd76fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "print(f\"Training set score: {ridge01.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test set score: {ridge01.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e28369",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge().fit(X_train, y_train)\n",
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "\n",
    "plt.plot(ridge.coef_, 's', label=\"Ridge alpha=1\")\n",
    "plt.plot(ridge10.coef_, '^', label=\"Ridge alpha=10\")\n",
    "plt.plot(ridge01.coef_, 'v', label=\"Ridge alpha=0.1\")\n",
    "plt.plot(lr.coef_, 'o', label=\"LinearRegression\")\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.hlines(0, 0, len(lr.coef_))\n",
    "plt.ylim(-25, 25)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_ridge_n_samples import plot_ridge_n_samples\n",
    "\n",
    "plot_ridge_n_samples()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d4f0c",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aee360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training set score: {lasso.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test set score: {lasso.score(X_test, y_test):.2f}\")\n",
    "print(f\"Number of features used: {np.sum(lasso.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_scores = {}\n",
    "testing_scores = {}\n",
    "\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=100000).fit(X_train, y_train)\n",
    "    traning_scores[alpha] = lasso.score(X_train, y_train)\n",
    "    testing_scores[alpha] = lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada52b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(traning_scores.keys(), traning_scores.values(), c=\"blue\", label=\"training\")\n",
    "plt.plot(testing_scores.keys(), testing_scores.values(), c=\"red\", label=\"testing\")\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we increase the default setting of \"max_iter\",\n",
    "# otherwise the model would warn us that we should increase max_iter.\n",
    "lasso001 = Lasso(alpha=0.01, max_iter=100000).fit(X_train, y_train)\n",
    "print(f\"Training set score: {lasso001.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test set score: {lasso001.score(X_test, y_test):.2f}\")\n",
    "print(f\"Number of features used: {np.sum(lasso001.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso00001 = Lasso(alpha=0.0001, max_iter=100000).fit(X_train, y_train)\n",
    "print(f\"Training set score: {lasso00001.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test set score: {lasso00001.score(X_test, y_test):.2f}\")\n",
    "print(f\"Number of features used: {np.sum(lasso00001.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lasso.coef_, 's', label=\"Lasso alpha=1\")\n",
    "plt.plot(lasso001.coef_, '^', label=\"Lasso alpha=0.01\")\n",
    "plt.plot(lasso00001.coef_, 'v', label=\"Lasso alpha=0.0001\")\n",
    "plt.plot(ridge01.coef_, 'o', label=\"Ridge alpha=0.1\")\n",
    "\n",
    "plt.legend(ncol=2, loc=(0, 1.05))\n",
    "plt.ylim(-25, 25)\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806ced6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "e_net = ElasticNet(alpha=0.001, l1_ratio=0.5, max_iter=10000).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training set score: {e_net.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test set score: {e_net.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02707a5a",
   "metadata": {},
   "source": [
    "## Linear models for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835758db",
   "metadata": {},
   "source": [
    "`ŷ = w[0] * x[0] + w[1] * x[1] + ... + w[p] * x[p] + b > 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b68eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_2d_separator import plot_2d_separator\n",
    "from helpers.plot_helpers import discrete_scatter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X, y = helpers.datasets.make_forge()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "for model, ax in zip([LinearSVC(max_iter=10000), LogisticRegression()], axes):\n",
    "    clf = model.fit(X, y)\n",
    "    plot_2d_separator(clf, X, fill=False, eps=0.5,ax=ax, alpha=.7)\n",
    "    discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(\"{}\".format(clf.__class__.__name__))\n",
    "    ax.set_xlabel(\"Feature 0\")\n",
    "    ax.set_ylabel(\"Feature 1\")\n",
    "    \n",
    "axes[0].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91937ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_linear_svc_regularization import plot_linear_svc_regularization\n",
    "\n",
    "plot_linear_svc_regularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training set score: {logreg.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test set score: {logreg.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f06fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg100 = LogisticRegression(max_iter=10000, C=100).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training set score: {logreg100.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test set score: {logreg100.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f63959",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg001 = LogisticRegression(max_iter=10000, C=0.01).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training set score: {logreg001.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test set score: {logreg001.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728dac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_scores = {}\n",
    "testing_scores = {}\n",
    "\n",
    "c_values = [0.01, 1, 10, 100, 500, 1000, 5000]\n",
    "\n",
    "for c in c_values:\n",
    "    logreg_diff = LogisticRegression(C=c, max_iter=100000).fit(X_train, y_train)\n",
    "    traning_scores[c] = logreg_diff.score(X_train, y_train)\n",
    "    testing_scores[c] = logreg_diff.score(X_test, y_test)\n",
    "    \n",
    "plt.plot(traning_scores.keys(), traning_scores.values(), c=\"blue\", label=\"training\")\n",
    "plt.plot(testing_scores.keys(), testing_scores.values(), c=\"red\", label=\"testing\")\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbd61f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "logreg100 = LogisticRegression(max_iter=10000, C=100).fit(X_train, y_train)\n",
    "logreg001 = LogisticRegression(max_iter=10000, C=0.01).fit(X_train, y_train)\n",
    "\n",
    "plt.plot(logreg.coef_.T, 'o', label=\"C=1\")\n",
    "plt.plot(logreg100.coef_.T, '^', label=\"C=100\")\n",
    "plt.plot(logreg001.coef_.T, 'v', label=\"C=0.001\")\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
    "plt.hlines(0, 0, cancer.data.shape[1])\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d71e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C, marker in zip([0.001, 1, 100], ['o', '^', 'v']):\n",
    "    lr_l1 = LogisticRegression(C=C, penalty=\"l1\", solver=\"liblinear\").fit(X_train, y_train)\n",
    "    print(f\"Training accuracy of l1 logreg with C={C:.3f}: {lr_l1.score(X_train, y_train):.2f}\")\n",
    "    print(f\"Test accuracy of l1 logreg with C={C:.3f}: {lr_l1.score(X_test, y_test):.2f}\")\n",
    "    plt.plot(lr_l1.coef_.T, marker, label=f\"C={C:.3f}\")\n",
    "\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
    "plt.hlines(0, 0, cancer.data.shape[1])\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.ylim(-5, 5)\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4bf41",
   "metadata": {},
   "source": [
    "## Linear models for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf0a56e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`w[0] * x[0] + w[1] * x[1] + ... + w[p] * x[p] + b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from helpers.tools import discrete_scatter\n",
    "\n",
    "X, y = make_blobs(random_state=42)\n",
    "\n",
    "discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.legend([\"Class 0\", \"Class 1\", \"Class 2\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16734d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm = LinearSVC().fit(X, y)\n",
    "\n",
    "print(\"Coefficient shape: \", linear_svm.coef_.shape)\n",
    "print(\"Intercept shape: \", linear_svm.intercept_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2888bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "\n",
    "line = np.linspace(-15, 15)\n",
    "\n",
    "for coef, intercept, color in zip(linear_svm.coef_, linear_svm.intercept_, ['b', 'r', 'g']):\n",
    "    plt.plot(line, -(line * coef[0] + intercept) / coef[1], c=color)\n",
    "    \n",
    "plt.ylim(-10, 15)\n",
    "plt.xlim(-10, 8)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.legend(['Class 0', 'Class 1', 'Class 2', 'Line class 0', 'Line class 1','Line class 2'], loc=(1.01, 0.3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d71407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_2d_separator import plot_2d_classification\n",
    "\n",
    "plot_2d_classification(linear_svm, X, fill=True, alpha=.7)\n",
    "discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "\n",
    "line = np.linspace(-15, 15)\n",
    "\n",
    "for coef, intercept, color in zip(linear_svm.coef_, linear_svm.intercept_,['b', 'r', 'g']):\n",
    "    plt.plot(line, -(line * coef[0] + intercept) / coef[1], c=color)\n",
    "\n",
    "plt.legend(['Class 0', 'Class 1', 'Class 2', 'Line class 0', 'Line class 1', 'Line class 2'], loc=(1.01, 0.3))\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882fc3b",
   "metadata": {},
   "source": [
    "## Strengths, weaknesses, and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4c1f7",
   "metadata": {},
   "source": [
    "**Parameters**:\n",
    "\n",
    "**Strengths**:\n",
    "\n",
    "**Weaknesses**:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
