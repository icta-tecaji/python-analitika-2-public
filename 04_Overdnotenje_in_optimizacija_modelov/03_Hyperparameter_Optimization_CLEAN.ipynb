{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc58e2f9",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ace209",
   "metadata": {},
   "source": [
    "## Parameter vs. Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0f949",
   "metadata": {},
   "source": [
    "A **model parameter** is a configuration variable that is internal to the model and whose value can be estimated from data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529278f",
   "metadata": {},
   "source": [
    "A **model hyperparameter** is a configuration that is external to the model and whose value cannot be estimated from data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e73b78",
   "metadata": {},
   "source": [
    "<table><thead><tr><th>PARAMETERS</th><th>HYPERPARAMETER</th></tr></thead><tbody><tr><td>They are required for making predictions</td><td>They are required for estimating the model parameters</td></tr><tr><td>They are estimated by optimization algorithms(Gradient Descent, Adam, Adagrad)</td><td>They are estimated by hyperparameter tuning</td></tr><tr><td>They are not set manually</td><td>They are set manually</td></tr><tr><td>The final parameters found after training will decide how the model will perform on unseen data</td><td>The choice of hyperparameters decide how efficient the training is. In gradient descent the learning rate decide how efficient and accurate the optimization process is in estimating the parameters</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b23eb7c",
   "metadata": {},
   "source": [
    "## About hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b469da",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning (or hyperparameter optimization) is the process of determining the right combination of hyperparameters that maximizes the model performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c802b55",
   "metadata": {},
   "source": [
    "- **`Manual hyperparameter tuning:`**\n",
    "    - Manual hyperparameter tuning involves experimenting with different sets of hyperparameters manually i.e. each trial with a set of hyperparameters will be performed by you. This technique will require a robust experiment tracker which could track a variety of variables from images, logs to system metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72dfdf5",
   "metadata": {},
   "source": [
    "- **`Automated hyperparameter tuning:`**\n",
    "    - Automated hyperparameter tuning utilizes already existing algorithms to automate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a5ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffe1221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf9e8a05",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ed8be",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e396e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14755404",
   "metadata": {},
   "source": [
    "- The Pros: It’s easy to implement. Can be easily parallelized.\n",
    "- The Pros: It’s insanely computationally expensive.\n",
    "- Should I use it: Probably not. Grid search is terribly inefficient. Even if you want to keep it simple, you’re better off using random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfcff8e",
   "metadata": {},
   "source": [
    "**Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9517a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dfaa0d1",
   "metadata": {},
   "source": [
    "<img src=\"images/img_01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7625e",
   "metadata": {},
   "source": [
    "- The Pros: Can be easily parallelized. Just as simple as grid search, but a bit better performance.\n",
    "- The Cons: While it gives better performance than grid search, it is still just as computationally intensive.\n",
    "- Should I use it: If trivial parallelization and simplicity are of utmost importance, go for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=0)\n",
    "distributions = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'])\n",
    "\n",
    "clf = RandomizedSearchCV(logistic, distributions, random_state=0, n_iter=20, n_jobs=1)\n",
    "search = clf.fit(iris.data, iris.target)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce29c13",
   "metadata": {},
   "source": [
    "**Bayesian Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e47f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec58a617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38164514",
   "metadata": {},
   "source": [
    "- The Pros: Bayesian optimization gives better results than both grid search and random search.\n",
    "- The Cons: It's not as easy to parallelize.\n",
    "- Should I Use It: In most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca565c",
   "metadata": {},
   "source": [
    "**Tree-structured Parzen estimators (TPE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70092de3",
   "metadata": {},
   "source": [
    "## Tips for hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99755956",
   "metadata": {},
   "source": [
    "- **Specifying an objective metric**\n",
    "- **Specifying multiple metrics for evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d06ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6481012",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_hastie_10_2(n_samples=8000, random_state=42)\n",
    "\n",
    "# The scorers can be either one of the predefined metric strings or a scorer\n",
    "# callable, like the one returned by make_scorer\n",
    "scoring = {\"AUC\": \"roc_auc\", \"Accuracy\": make_scorer(accuracy_score)}\n",
    "\n",
    "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
    "# parameter setting that has the best cross-validated AUC score.\n",
    "# That estimator is made available at ``gs.best_estimator_`` along with\n",
    "# parameters like ``gs.best_score_``, ``gs.best_params_`` and\n",
    "# ``gs.best_index_``\n",
    "gs = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid={\"min_samples_split\": range(2, 403, 20)},\n",
    "    scoring=scoring,\n",
    "    refit=\"AUC\",\n",
    "    n_jobs=2,\n",
    "    return_train_score=True,\n",
    ")\n",
    "gs.fit(X, y)\n",
    "results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ced3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 13))\n",
    "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\", fontsize=16)\n",
    "\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(0, 402)\n",
    "ax.set_ylim(0.73, 1)\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "X_axis = np.array(results[\"param_min_samples_split\"].data, dtype=float)\n",
    "\n",
    "for scorer, color in zip(sorted(scoring), [\"g\", \"k\"]):\n",
    "    for sample, style in ((\"train\", \"--\"), (\"test\", \"-\")):\n",
    "        sample_score_mean = results[\"mean_%s_%s\" % (sample, scorer)]\n",
    "        sample_score_std = results[\"std_%s_%s\" % (sample, scorer)]\n",
    "        ax.fill_between(\n",
    "            X_axis,\n",
    "            sample_score_mean - sample_score_std,\n",
    "            sample_score_mean + sample_score_std,\n",
    "            alpha=0.1 if sample == \"test\" else 0,\n",
    "            color=color,\n",
    "        )\n",
    "        ax.plot(\n",
    "            X_axis,\n",
    "            sample_score_mean,\n",
    "            style,\n",
    "            color=color,\n",
    "            alpha=1 if sample == \"test\" else 0.7,\n",
    "            label=\"%s (%s)\" % (scorer, sample),\n",
    "        )\n",
    "\n",
    "    best_index = np.nonzero(results[\"rank_test_%s\" % scorer] == 1)[0][0]\n",
    "    best_score = results[\"mean_test_%s\" % scorer][best_index]\n",
    "\n",
    "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "    ax.plot(\n",
    "        [\n",
    "            X_axis[best_index],\n",
    "        ]\n",
    "        * 2,\n",
    "        [0, best_score],\n",
    "        linestyle=\"-.\",\n",
    "        color=color,\n",
    "        marker=\"x\",\n",
    "        markeredgewidth=3,\n",
    "        ms=8,\n",
    "    )\n",
    "\n",
    "    # Annotate the best score for that scorer\n",
    "    ax.annotate(\"%0.2f\" % best_score, (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339df70b",
   "metadata": {},
   "source": [
    "- **Composite estimators and parameter spaces**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4782820d",
   "metadata": {},
   "source": [
    "## Hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5cc739",
   "metadata": {},
   "source": [
    "**Hyperopt is an open source hyperparameter tuning library that uses a Bayesian approach to find the best values for the hyperparameters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b344d97",
   "metadata": {},
   "source": [
    "Install hyperopt from PyPI: `pip install hyperopt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f0063e",
   "metadata": {},
   "source": [
    "Documentation: http://hyperopt.github.io/hyperopt/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741b2bc",
   "metadata": {},
   "source": [
    "Tutorial: https://github.com/hyperopt/hyperopt/wiki/FMin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb181794",
   "metadata": {},
   "source": [
    "Hyperopt's job is to find the best value of a scalar-valued, possibly-stochastic function over a set of possible arguments to that function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60729a",
   "metadata": {},
   "source": [
    "Currently three algorithms are implemented in hyperopt:\n",
    "- Random Search\n",
    "- Tree of Parzen Estimators (TPE)\n",
    "- Adaptive TPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443bfdd",
   "metadata": {},
   "source": [
    "> [Hyperopt-sklearn](https://github.com/hyperopt/hyperopt-sklearn) is Hyperopt-based model selection among machine learning algorithms in scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144b94a",
   "metadata": {},
   "source": [
    "### Example: Water quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fc02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9eb5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data and info\n",
    "data = pd.read_csv('data/water_potability.csv')\n",
    "\n",
    "# remove missing values\n",
    "data = data.dropna()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train and test\n",
    "X = data.drop(['Potability'], axis = 1)\n",
    "y = data['Potability']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=200)\n",
    "\n",
    "# build the model\n",
    "model = RandomForestClassifier(n_estimators=300, max_features='sqrt', random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# print out the score accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b59dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in hyperopt values\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98aea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function we want to minimise\n",
    "def objective(n_estimators):\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                   max_features='sqrt',\n",
    "                                   random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cddbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the values to search over for n_estimators\n",
    "search_space = hp.randint('n_estimators', 200, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyperparam tuning algorithm\n",
    "algorithm=tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = fmin(\n",
    "  fn=objective,\n",
    "  space=search_space,\n",
    "  algo=algorithm,\n",
    "  max_evals=10) # v praksi 200+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ccf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba59f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine the function usng a wider range of hyperparameters\n",
    "def objective(search_space):\n",
    "    model = RandomForestClassifier(**search_space, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "# new search space\n",
    "search_space={'n_estimators':hp.randint('n_estimators',200,1000),\n",
    "              \n",
    "              'max_depth': hp.randint('max_depth',10,200),           \n",
    "            \n",
    "            'min_samples_split':hp.uniform('min_samples_split',0,1),   \n",
    "             'min_samples_leaf':hp.randint('min_samples_leaf',1,10),\n",
    "              \n",
    "               'criterion':hp.choice('criterion', ['gini','entropy']),\n",
    "                \n",
    "           'max_features':hp.choice('max_features',['sqrt', 'log2']) }\n",
    "\n",
    "# implement Hyperopt\n",
    "best_params = fmin(\n",
    "  fn=objective,\n",
    "  space=search_space,\n",
    "  algo=algorithm,\n",
    "  max_evals=15) # v praksi 200+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_eval(search_space, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d0425",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53767d",
   "metadata": {},
   "source": [
    "**An open source hyperparameter optimization framework to automate hyperparameter search.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa93fb1",
   "metadata": {},
   "source": [
    "Web page: https://optuna.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1873f7f9",
   "metadata": {},
   "source": [
    "Docs: https://optuna.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e868a7c7",
   "metadata": {},
   "source": [
    "Tutorial: https://optuna.readthedocs.io/en/stable/tutorial/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cee67c",
   "metadata": {},
   "source": [
    "Optuna can be installed with pip: `pip install optuna`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e1a1d1",
   "metadata": {},
   "source": [
    "Optuna is framework agnostic. You can use it with any machine learning or deep learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53462fd",
   "metadata": {},
   "source": [
    "Optuna has modern functionalities as follows:\n",
    "- Lightweight, versatile, and platform agnostic architecture. Handle a wide variety of tasks with a simple installation that has few requirements.\n",
    "- Pythonic search spaces. Define search spaces using familiar Python syntax including conditionals and loops.\n",
    "- Efficient optimization algorithms. Adopt state-of-the-art algorithms for sampling hyperparameters and efficiently pruning unpromising trials.\n",
    "- Easy parallelization. Scale studies to tens or hundreds of workers with little or no changes to the code.\n",
    "- Quick visualization. Inspect optimization histories from a variety of plotting functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafa70f",
   "metadata": {},
   "source": [
    "Optuna provides the following sampling algorithms:\n",
    "- Grid Search implemented in GridSampler\n",
    "- Random Search implemented in RandomSampler\n",
    "- Tree-structured Parzen Estimator algorithm implemented in TPESampler\n",
    "- CMA-ES based algorithm implemented in CmaEsSampler\n",
    "- Algorithm to enable partial fixed parameters implemented in PartialFixedSampler\n",
    "- Nondominated Sorting Genetic Algorithm II implemented in NSGAIISampler\n",
    "- A Quasi Monte Carlo sampling algorithm implemented in QMCSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291490e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24970d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective():\n",
    "    iris = sklearn.datasets.load_iris()  # Prepare the data.\n",
    "    \n",
    "    clf = sklearn.ensemble.RandomForestClassifier(    \n",
    "        n_estimators=5, max_depth=3)  # Define the model.\n",
    "    \n",
    "    return sklearn.model_selection.cross_val_score(\n",
    "        clf, iris.data, iris.target, n_jobs=-1, cv=3).mean()  # Train and evaluate the model.\n",
    "\n",
    "print('Accuracy: {}'.format(objective()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize hyperparameters of the model\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    iris = sklearn.datasets.load_iris()\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 2, 20)\n",
    "    max_depth = int(trial.suggest_float('max_depth', 1, 32, log=True))\n",
    "    \n",
    "    clf = sklearn.ensemble.RandomForestClassifier(\n",
    "        n_estimators=n_estimators, max_depth=max_depth)\n",
    "    \n",
    "    return sklearn.model_selection.cross_val_score(\n",
    "        clf, iris.data, iris.target, n_jobs=-1, cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b74246",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm\n",
    "\n",
    "def objective(trial):\n",
    "    iris = sklearn.datasets.load_iris()\n",
    "\n",
    "    classifier = trial.suggest_categorical('classifier', ['RandomForest', 'SVC'])\n",
    "    \n",
    "    if classifier == 'RandomForest':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 2, 20)\n",
    "        max_depth = int(trial.suggest_float('max_depth', 1, 32, log=True))\n",
    "\n",
    "        clf = sklearn.ensemble.RandomForestClassifier(\n",
    "            n_estimators=n_estimators, max_depth=max_depth)\n",
    "    else:\n",
    "        c = trial.suggest_float('svc_c', 1e-10, 1e10, log=True)\n",
    "        \n",
    "        clf = sklearn.svm.SVC(C=c, gamma='auto')\n",
    "\n",
    "    return sklearn.model_selection.cross_val_score(\n",
    "        clf, iris.data, iris.target, n_jobs=-1, cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde411c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c50c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4badc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ae6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study, params=['n_estimators', 'max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb55a00",
   "metadata": {},
   "source": [
    "> Optuna Dashboard: https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
