{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fdaa8ec",
   "metadata": {},
   "source": [
    "# Working with latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d660a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1339b5",
   "metadata": {},
   "source": [
    "Geo-based features are a class of features present in range of datasets. These features contain records about the geographical location of a place/point in space. Features like Longitudes, Latitudes, and Address are geo-features that need to be engineered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv(\"data/stations_clean.csv\")\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "station2537 = stations.iloc[0]\n",
    "station2572 = stations.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52947dcb",
   "metadata": {},
   "source": [
    "## Manhattan distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dfa0b5",
   "metadata": {},
   "source": [
    "The Manhattan distance is the sum of the horizontal and vertical distance between two points. Let’s demonstrate this below using the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bdaa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(lat1, lng1, lat2, lng2):\n",
    "    a = np.abs(lat2 -lat1)\n",
    "    b = np.abs(lng1 - lng2)\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b90a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_distance(station2537['latitude'], station2537['longitude'], station2572['latitude'], station2572['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c693aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasist MODULE\n",
    "from datasist.feature_engineering import manhattan_distance\n",
    "\n",
    "manhattan_distance(station2537['latitude'], station2537['longitude'], station2572['latitude'], station2572['longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4bb341",
   "metadata": {},
   "source": [
    "## Haversine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3359463",
   "metadata": {},
   "source": [
    "The Haversine distance is the great-circle distance between two points on a sphere, given their longitudes and latitudes. It’s very important in navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "haversine_array(station2537['latitude'], station2537['longitude'], station2572['latitude'], station2572['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasist MODULE\n",
    "from datasist.feature_engineering import haversine_distance\n",
    "\n",
    "haversine_distance(station2537['latitude'], station2537['longitude'], station2572['latitude'], station2572['longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373737d",
   "metadata": {},
   "source": [
    "## Bearing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8c011",
   "metadata": {},
   "source": [
    "The bearing is the compass direction used to travel from a starting point, and must be within the range 0 to 360."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearing_array(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0babb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearing_array(station2537['latitude'], station2537['longitude'], station2572['latitude'], station2572['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasist MODULE\n",
    "from datasist.feature_engineering import bearing\n",
    "\n",
    "bearing(station2537['latitude'], station2537['longitude'], station2572['latitude'], station2572['longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c473447",
   "metadata": {},
   "source": [
    "## Example: Bike Sharing Demand dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f15200",
   "metadata": {},
   "source": [
    "Cilj: Predict daily ridership totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the trips dataset\n",
    "trips = pd.read_csv(\"data/bike_trips_clean.csv\")\n",
    "trips.dropna(inplace=True)\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the stations dataset\n",
    "stations = pd.read_csv(\"data/stations_clean.csv\")\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a2ab2",
   "metadata": {},
   "source": [
    "- Preverimo in uredimo podatkovne tipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae318be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips[\"start_time\"] = pd.to_datetime(trips[\"start_time\"])\n",
    "trips[\"trip_id\"] = trips[\"trip_id\"].astype(\"int\")\n",
    "trips[\"end_station_id\"] = trips[\"end_station_id\"].astype(\"int\")\n",
    "trips[\"start_station_id\"] = trips[\"start_station_id\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe02a9",
   "metadata": {},
   "source": [
    "- Uredimo časovne značilke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ed3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_features(trips):\n",
    "    \"\"\"Takes a date and returns day of week, month, hour and \n",
    "    whether it is a weekday/workhour\"\"\"\n",
    "    ser = trips[\"start_time\"]\n",
    "    trips[\"date\"] = ser.dt.date\n",
    "    trips[\"time\"] = ser.dt.time\n",
    "    trips[\"year\"] = ser.dt.year\n",
    "    trips[\"month\"] = ser.dt.month\n",
    "    trips[\"day\"] = ser.dt.day\n",
    "    trips[\"dow\"] = ser.dt.dayofweek\n",
    "    trips[\"dow_name\"] = ser.dt.day_name()\n",
    "    trips[\"hour\"] = ser.dt.hour\n",
    "    trips[\"weekday\"] = trips[\"dow\"].apply(lambda x: 1 if x < 5 else 0)\n",
    "    trips[\"workhour\"] = trips[\"hour\"].apply(lambda x: 1 if x in [8,17] else 0)\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_full = get_time_features(trips)\n",
    "trips_full.drop(columns= [\"start_time\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ba511",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd24e75",
   "metadata": {},
   "source": [
    "To get a quick understanding of the periodic patterns of the data, let us have a look at the average demand per hour during a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_full.groupby('dow_name').dow_name.count().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b2b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_full.groupby([\"dow_name\", \"hour\"]).dow_name.count()[\"Friday\"].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95069e6",
   "metadata": {},
   "source": [
    "Ridership totals during different months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd02bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsByMonth = trips_full.groupby('month').month.count()\n",
    "tripsByMonth.index = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                      'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "ax = sns.barplot(x='index', y='month', data=tripsByMonth.reset_index(), color='red')\n",
    "ax.figure.set_size_inches(7,4)\n",
    "sns.set_style(style='white')\n",
    "ax.axes.set_title('Total Rides in Each Month', fontsize=24)\n",
    "ax.set_xlabel('Month', size=20)\n",
    "ax.set_ylabel('Rides', size=20)\n",
    "ax.tick_params(labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ec054",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_by_year_month = trips_full\n",
    "trips_by_year_month = trips_by_year_month.groupby(['month','year']).month.count()\n",
    "trips_by_year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba807e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsFullYears = trips_full[trips_full['year'].isin([2014,2015])]\n",
    "tripsFullYears = tripsFullYears.groupby(['month', 'year'])[\"trip_id\"].count()\n",
    "tripsByMonth = pd.DataFrame(tripsFullYears)\n",
    "ax = sns.barplot(x='month', y=\"trip_id\", hue='year', data=tripsByMonth.reset_index(), color='red')\n",
    "ax.figure.set_size_inches(10,5)\n",
    "sns.set_style(style='white')\n",
    "ax.axes.set_title('Total Rides in Each Month', fontsize=24)\n",
    "ax.set_xlabel('Month', size=20)\n",
    "ax.set_ylabel('Rides', size=20)\n",
    "ax.tick_params(labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e662a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa75d18",
   "metadata": {},
   "source": [
    "Can we predict daily ridership totals based off of the weather?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"data/austin_weather.csv\", na_values=\"-\")\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"Events\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97508206",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"data/austin_weather.csv\", na_values=\"-\")\n",
    "\n",
    "weather_new = pd.DataFrame()\n",
    "weather_new[\"date\"] = pd.to_datetime(weather[\"Date\"])\n",
    "weather_new['rain'] = np.where(weather['Events'].str.contains('Rain'), 1, 0)\n",
    "weather_new['thunderstorm'] = np.where(weather['Events'].str.contains('Thunderstorm'), 1, 0)\n",
    "weather_new['fog'] = np.where(weather['Events'].str.contains('Fog'), 1, 0)\n",
    "weather_new['snow'] = np.where(weather['Events'].str.contains('Snow'), 1, 0)\n",
    "weather_new['temp_avg'] = weather['TempAvgF'].astype(\"int\")\n",
    "weather_new['humidity_avg'] = weather['HumidityAvgPercent'].astype(\"float\")\n",
    "weather_new['wind_avg'] = weather['WindAvgMPH'].astype(\"float\")\n",
    "weather_new['wind_gust'] = weather['WindGustMPH'].astype(\"float\")\n",
    "# Convert traces of rain to .001 inches of rain to recognize that there was perciptation \n",
    "# but it was a value less than what could be measured.\n",
    "weather_new['precipitation_inches'] = np.where(weather['PrecipitationSumInches'] == 'T', 0.001, weather['PrecipitationSumInches'])\n",
    "weather_new['precipitation_inches'] = weather_new['precipitation_inches'].astype(\"float\")\n",
    "# select the range\n",
    "weather_new = weather_new[(weather_new['date'] >= '2014-01-01') & (weather_new['date'] <= '2015-12-31')]\n",
    "weather_new = weather_new.set_index('date', drop=True)\n",
    "weather_new = weather_new.fillna(weather_new.mean(numeric_only=True),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace44a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c1ffa",
   "metadata": {},
   "source": [
    "Next lets clean group the ridership data by dates and create our targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af71e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ddb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = trips_full[trips_full['year'].isin([2014,2015])]\n",
    "trips = trips.groupby(['date'])[\"trip_id\"].count().to_frame()\n",
    "trips.columns = ['trip_count']\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_features(trips):\n",
    "    \"\"\"Takes a date and returns day of week, month, hour and \n",
    "    whether it is a weekday/workhour\"\"\"\n",
    "    ser = pd.to_datetime(trips.index)\n",
    "    trips[\"year\"] = ser.year\n",
    "    trips[\"month\"] = ser.month\n",
    "    trips[\"day\"] = ser.day\n",
    "    trips[\"dow\"] = ser.dayofweek\n",
    "    trips[\"weekday\"] = trips[\"dow\"].apply(lambda x: 1 if x < 5 else 0)\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f094db",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = get_time_features(trips).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f809704",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6db810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join ridership and weather data together\n",
    "trips_with_weather = pd.merge(right=trips, left=weather_new, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ba02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_with_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_scores(trained_model, X_train, X_test, y_train, y_test):\n",
    "    pred = trained_model.predict(X_test)\n",
    "    mse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "    print(f'Mean error: {mse:.5} min ({mse/np.mean(pred)*100:3.3}%)')\n",
    "    print(f\"Training set score: {trained_model.score(X_train, y_train):.2f}\")\n",
    "    print(f\"Test set score: {trained_model.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9482f82",
   "metadata": {},
   "source": [
    "Prepare data for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    trips_with_weather.drop(columns=[\"trip_count\"]), trips_with_weather[\"trip_count\"], test_size = .3, random_state = 13, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a41d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "reg = Ridge(alpha = 0.5)\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9fc58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6b57e",
   "metadata": {},
   "source": [
    "Wow this did terribly lets graph observed vs predicted to see visually how bad it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_vs_actual(trained_model, X_train, X_test, y_train, y_test):\n",
    "    rideCountsPredictions = trained_model.predict(X_test)\n",
    "    rideCountsActual = y_test\n",
    "    ax = sns.regplot(x=rideCountsActual, y=rideCountsPredictions)\n",
    "    ax.figure.set_size_inches(10,6)\n",
    "    ax.axes.set_title('Predictions Vs. Actual', fontsize=24)\n",
    "    ax.set_xlabel('Actual', fontsize=20)\n",
    "    ax.set_ylabel('Predictions', fontsize=20)\n",
    "    ax.tick_params(labelsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_vs_actual(reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f92ed",
   "metadata": {},
   "source": [
    "Lets try some more feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e287bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "reg = Lasso(alpha=0.1)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "get_scores(reg, X_train, X_test, y_train, y_test)\n",
    "plot_prediction_vs_actual(reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da404099",
   "metadata": {},
   "source": [
    "lets take a look at what dates are the outliers. It looks like the core of the data is folowing a trend line of y=x. However, there are a significant amount of days that are extreme outliers, total rides > 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlierTrips = trips_with_weather[trips_with_weather[\"trip_count\"] > 1500]\n",
    "outlierTrips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a415dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def spring_break_woo(date):\n",
    "    if (date >= datetime(2015, 3, 14)) & (date <= datetime(2015, 3, 23)):\n",
    "        return 1\n",
    "    if (date >= datetime(2014, 3, 8)) & (date <= datetime(2014, 3, 17)):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_with_weather['spring_break'] = trips_with_weather.apply(lambda row: spring_break_woo(row.name), axis=1)\n",
    "trips_with_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2c01d",
   "metadata": {},
   "source": [
    "Quickly lets check to see if this made any improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064bac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(trips_with_weather.drop(columns=[\"trip_count\"]), \n",
    "                                                        trips_with_weather[\"trip_count\"], \n",
    "                                                        test_size = .3, \n",
    "                                                        random_state = 13, shuffle=True)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    get_scores(model, X_train, X_test, y_train, y_test)\n",
    "    plot_prediction_vs_actual(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829aca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(Lasso(alpha=0.1), trips_with_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3159c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "run_model(DecisionTreeRegressor(max_depth=15), trips_with_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f3f529",
   "metadata": {},
   "source": [
    "Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638cd317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(trips_with_weather.drop(columns=[\"trip_count\"]), \n",
    "                                                        trips_with_weather[\"trip_count\"], \n",
    "                                                        test_size = .3, \n",
    "                                                        random_state = 13, shuffle=True)\n",
    "    \n",
    "    \n",
    "    vars_categorical = [\"year\", \"month\", \"day\", \"dow\", \"weekday\"]\n",
    "    \n",
    "    # then we instantiate the imputer within a pipeline\n",
    "    one_hot_encoder = Pipeline(steps=[\n",
    "        ('one_hot_encoder', OneHotEncoder(categories='auto', drop='first', sparse_output=False)),\n",
    "    ])\n",
    "\n",
    "    # then we put the features list and the imputer in the column transformer\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('cat_encoder', one_hot_encoder, vars_categorical)\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # now we fit the preprocessor\n",
    "    preprocessor.fit(X_train)\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    get_scores(model, X_train, X_test, y_train, y_test)\n",
    "    plot_prediction_vs_actual(model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "run_model(Lasso(alpha=0.1), trips_with_weather)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
