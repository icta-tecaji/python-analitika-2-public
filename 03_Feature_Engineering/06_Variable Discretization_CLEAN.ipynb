{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73ac91a",
   "metadata": {},
   "source": [
    "# Variable Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5044bfc",
   "metadata": {},
   "source": [
    "**Discretization, or binning**, is the process of **transforming continuous variables into discrete\n",
    "variables** by creating a set of contiguous intervals, also called bins, that span the range of\n",
    "the variable values. Discretization is used to **change the distribution of skewed variables**\n",
    "and to **minimize the influence of outliers**, and hence improve the performance of some\n",
    "machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7140080",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.read_csv(\"data/boston.csv\")\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb863603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from helpers.datasets import make_wave\n",
    "\n",
    "X, y = make_wave(n_samples=100)\n",
    "\n",
    "line = np.linspace(-3, 3, 1000, endpoint=False).reshape(-1, 1)\n",
    "\n",
    "reg = DecisionTreeRegressor(min_samples_split=3).fit(X, y)\n",
    "plt.plot(line, reg.predict(line), label=\"decision tree\")\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "plt.plot(line, reg.predict(line), label=\"linear regression\")\n",
    "\n",
    "plt.plot(X[:, 0], y, 'o', c='k')\n",
    "plt.ylabel(\"Regression output\")\n",
    "plt.xlabel(\"Input feature\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1434bc18",
   "metadata": {},
   "source": [
    "## Dividing the variable into intervals of equal width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912925f",
   "metadata": {},
   "source": [
    "**In equal-width discretization, the variable values are sorted into intervals of the same\n",
    "width.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fabf929",
   "metadata": {},
   "source": [
    "    Width = (Max(X) - Min(X)) / Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f55a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = boston.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('MEDV', axis=1), data['MEDV'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93765f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the range of the LSTAT variable, that is, the difference between its maximum and minimum values:\n",
    "lstat_range = X_train['LSTAT'].max() - X_train['LSTAT'].min()\n",
    "\n",
    "# Let's determine the interval width, which is the variable's value range divided by the number of bins:\n",
    "inter_width = int(lstat_range / 10)\n",
    "\n",
    "# Let's capture in new variables, the rounded minimum and maximum values of LSTAT:\n",
    "min_value = int(np.floor( X_train['LSTAT'].min()))\n",
    "max_value = int(np.ceil( X_train['LSTAT'].max()))\n",
    "\n",
    "print(min_value, max_value, inter_width)\n",
    "\n",
    "#Let's create a list with the interval limits using list comprehension and print out the limits:\n",
    "intervals = [i for i in range(min_value, max_value + inter_width, inter_width)]\n",
    "print(intervals)\n",
    "\n",
    "# Let's discretize LSTAT and capture the discretized variable in a new column in the dataframe:\n",
    "X_train['lstat_disc'] = pd.cut(x=X_train['LSTAT'], bins=intervals, include_lowest=True)\n",
    "\n",
    "#Let's print the top 10 observations of the discretized and original variable, side by side:\n",
    "print(X_train[['LSTAT', 'lstat_disc']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09038acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the number of observations per interval:\n",
    "print(X_train.groupby('lstat_disc')['LSTAT'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb233bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's discretize LSTAT in the test set using pandas' cut() method:\n",
    "X_test['lstat_disc'] = pd.cut(x=X_test['LSTAT'], bins=intervals, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = X_train['lstat_disc'].value_counts() / len(X_train)\n",
    "t2 = X_test['lstat_disc'].value_counts() / len(X_test)\n",
    "tmp = pd.concat([t1, t2], axis=1)\n",
    "tmp.columns = ['train', 'test']\n",
    "tmp.plot.bar()\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Number of observations per bin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b91017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "data = boston.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('MEDV', axis=1), data['MEDV'], test_size=0.3, random_state=0)\n",
    "\n",
    "# Let's create an equal-width discretizer with scikit-learn by setting its strategy to uniform:\n",
    "disc = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.fit(X_train[['LSTAT', 'DIS', 'RM']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t = disc.transform(X_train[['LSTAT', 'DIS', 'RM']])\n",
    "test_t = disc.transform(X_test[['LSTAT', 'DIS', 'RM']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can inspect the bin boundaries learned by the transformer\n",
    "disc.bin_edges_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54944d1",
   "metadata": {},
   "source": [
    "- Equal Width doesnâ€™t improve the value spread\n",
    "- It can handle outliers\n",
    "- Can be combined with categorical encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e1585",
   "metadata": {},
   "source": [
    "## Sorting the variable values in intervals of equal frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = boston.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('MEDV', axis=1), data['MEDV'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c4278",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "\n",
    "disc.fit(X_train[['LSTAT', 'DIS', 'RM']])\n",
    "\n",
    "train_t = disc.transform(X_train[['LSTAT', 'DIS', 'RM']])\n",
    "test_t = disc.transform(X_test[['LSTAT', 'DIS', 'RM']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c837f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.bin_edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dbc69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(train_t, columns =['LSTAT', 'DIS', 'RM'])\n",
    "X_test = pd.DataFrame(test_t, columns =['LSTAT', 'DIS', 'RM'])\n",
    "t1 = X_train['LSTAT'].value_counts() / len(X_train)\n",
    "t2 = X_test['LSTAT'].value_counts() / len(X_test)\n",
    "tmp = pd.concat([t1, t2], axis=1)\n",
    "tmp.columns = ['train', 'test']\n",
    "tmp.plot.bar()\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Number of observations per bin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b03419d",
   "metadata": {},
   "source": [
    "- Equal Frequency does improve the value spread\n",
    "- It can handle outliers\n",
    "- Can be combined with categorical encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcac26a",
   "metadata": {},
   "source": [
    "## Performing discretization followed by categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = boston.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('MEDV', axis=1), data['MEDV'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = KBinsDiscretizer(n_bins=10, encode='onehot', strategy='quantile')\n",
    "\n",
    "disc.fit(X_train[['LSTAT', 'DIS', 'RM']])\n",
    "\n",
    "train_t = disc.transform(X_train[['LSTAT', 'DIS', 'RM']])\n",
    "test_t = disc.transform(X_test[['LSTAT', 'DIS', 'RM']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f251fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.bin_edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd53912",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07139e08",
   "metadata": {},
   "source": [
    "## Allocating the variable values in arbitrary intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = boston.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('MEDV', axis=1), data['MEDV'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LSTAT'].hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a list with the arbitrary interval limits, setting the upper limit to infinity to accommodate bigger values:\n",
    "intervals = [0, 10, 20, 30, np.Inf]\n",
    "\n",
    "# Let's create a list with the interval limits as labels, that is, strings:\n",
    "labels = ['0-10', '10-20', '20-30', '>30']\n",
    "\n",
    "# Let's discretize the LSTAT variable\n",
    "data['lstat_labels'] = pd.cut(data['LSTAT'], bins=intervals, labels=labels, include_lowest=True)\n",
    "data['lstat_intervals'] = pd.cut(data['LSTAT'], bins=intervals, labels=None, include_lowest=True)\n",
    "\n",
    "data[['LSTAT','lstat_labels', 'lstat_intervals']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lstat_intervals'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab86fe",
   "metadata": {},
   "source": [
    "## Using decision trees for discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "data = boston.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('MEDV', axis=1), data['MEDV'], test_size=0.3, random_state=0)\n",
    "\n",
    "# Let's assemble a decision tree to predict the MEDV target, setting the maximum depth to 3 and random_state for reproducibility\n",
    "tree_model = DecisionTreeRegressor(max_depth=3, random_state=0)\n",
    "\n",
    "# Let's fit the decision tree using the LSTAT variable to predict the MEDV target\n",
    "tree_model.fit(X_train['LSTAT'].to_frame(), y_train)\n",
    "\n",
    "X_train['lstat_tree'] = tree_model.predict(X_train['LSTAT'].to_frame())\n",
    "\n",
    "# Let's explore the end leaves, that is, bins, the tree created:\n",
    "X_train['lstat_tree'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now discretize the LSTAT variable in the test set:\n",
    "X_test['lstat_tree'] = tree_model.predict(X_test['LSTAT'].to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6c8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_test, y_test],axis=1).groupby(['lstat_tree'])['MEDV'].mean().plot()\n",
    "plt.title('Monotonic relationship between discretised LSTAT and target')\n",
    "plt.ylabel('MEDV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = X_train['lstat_tree'].value_counts() / len(X_train)\n",
    "t2 = X_test['lstat_tree'].value_counts() / len(X_test)\n",
    "tmp = pd.concat([t1, t2], axis=1)\n",
    "tmp.columns = ['train', 'test']\n",
    "tmp.plot.bar()\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Number of observations per bin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2df6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.discretisation import DecisionTreeDiscretiser\n",
    "\n",
    "treeDisc = DecisionTreeDiscretiser(cv=10, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   variables=['LSTAT', 'RM', 'DIS'], \n",
    "                                   regression=True, \n",
    "                                   param_grid={'max_depth': [1,2,3,4]})\n",
    "\n",
    "treeDisc.fit(X_train, y_train)\n",
    "treeDisc.binner_dict_['LSTAT'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f758f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t = treeDisc.transform(X_train)\n",
    "test_t = treeDisc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93cf5a",
   "metadata": {},
   "source": [
    "- Decision Tree does not improve the value spread\n",
    "- It can handle outliers well as trees are robust to outliers.\n",
    "- Creates monotonic relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6167dab0",
   "metadata": {},
   "source": [
    "## Example: Wave regression dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcfe38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_wave(n_samples=100)\n",
    "\n",
    "kb = KBinsDiscretizer(n_bins=10, strategy='uniform')\n",
    "kb.fit(X)\n",
    "print(\"bin edges: \\n\", kb.bin_edges_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3484cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binned = kb.transform(X)\n",
    "X_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307741ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:10])\n",
    "X_binned.toarray()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = KBinsDiscretizer(n_bins=10, strategy='uniform', encode='onehot-dense')\n",
    "kb.fit(X)\n",
    "X_binned = kb.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_binned = kb.transform(line)\n",
    "\n",
    "reg = LinearRegression().fit(X_binned, y)\n",
    "plt.plot(line, reg.predict(line_binned), label='linear regression binned')\n",
    "\n",
    "reg = DecisionTreeRegressor(min_samples_split=3).fit(X_binned, y)\n",
    "plt.plot(line, reg.predict(line_binned), label='decision tree binned')\n",
    "plt.plot(X[:, 0], y, 'o', c='k')\n",
    "plt.vlines(kb.bin_edges_[0], -3, 3, linewidth=1, alpha=.2)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylabel(\"Regression output\")\n",
    "plt.xlabel(\"Input feature\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "89ea9477443f71924be38d393f41424c35ee7c7ee5571933398f9912d93043f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
